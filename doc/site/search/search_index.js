var __index = {"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"VLabApp documentation","text":""},{"location":"index.html#getting-started","title":"Getting started","text":"<ul> <li>Installation</li> <li>Tutorial</li> </ul>"},{"location":"index.html#reference","title":"Reference","text":"<ul> <li>File naming conventions and supported formats</li> <li>Registration module</li> <li>Z-Projection module</li> <li>Segmentation module</li> <li>Cell tracking module</li> <li>Graph filtering module</li> <li>Events selection module</li> <li>Pipeline module</li> <li>Tools:<ul> <li>View image, mask and graph</li> <li>View registration matrix</li> <li>View metadata</li> <li>File organization</li> <li>File conversion (masks and graphs)</li> <li>File conversion (lossy preview)</li> <li>Image cropping</li> <li>Ground truth generator</li> </ul> </li> <li>Plugins</li> </ul>"},{"location":"index.html#citation","title":"Citation","text":"<p>If you use VLabApp in your research, please cite the VLabApp paper:</p> <p>J. Dorier, A. Ravera and A. Vjestica. In preparation</p> <p>If you use the registration module with stackreg, please cite the following publication:</p> <p>P. Thevenaz, U. E. Ruttimann and M. Unser (1998). A pyramid approach to subpixel registration based on intensity. IEEE Transactions on Image Processing, 7(1), 27\u201341.</p> <p>If you use the segmentation module with Cellpose, please cite the Cellpose 1.0 publication:</p> <p>C. Stringer, T. Wang, M. Michaelos and M. Pachitariu (2021). Cellpose: a generalist algorithm for cellular segmentation. Nature Methods 18, 100\u2013106.</p> <p>If you fine-tune a Cellpose model, please cite the Cellpose 2.0 publication:</p> <p>M. Pachitariu and C. Stringer (2022). Cellpose 2.0: how to train your own model. Nature Methods 19, 1634\u20131641.</p> <p>If you use the segmentation module with the <code>cyto3</code> Cellpose model, please cite the Cellpose 3.0 publication:</p> <p>C. Stringer and M. Pachitariu (2025). Cellpose3: one-click image restoration for improved cellular segmentation. Nature Methods 22, 592-599.</p>"},{"location":"index.html#other-tools-and-libraries-used-in-this-project","title":"Other tools and libraries used in this project","text":"<ul> <li> <p>igraph</p> <p>G. Csardi and T. Nepusz (2006). The igraph software package for complex network research. InterJournal, Complex Systems, 1695.</p> </li> <li> <p>napari</p> <p>napari contributors (2019). napari: a multi-dimensional image viewer for python. doi:10.5281/zenodo.3555620</p> </li> <li> <p>NumPy</p> <p>C.R. Harris, K.J. Millman, S.J. van der Walt et al. (2020). Array programming with NumPy. Nature 585, 357\u2013362.</p> </li> <li> <p>OpenCV</p> <p>G. Bradski (2000). The OpenCV Library. Dr. Dobb's Journal of Software Tools.</p> </li> <li> <p>Python</p> </li> <li> <p>Qt</p> </li> <li> <p>scikit-image</p> <p>S. van der Walt, J. L. Sch\u00f6nberger, J. Nunez-Iglesias et al. (2014). scikit-image: Image processing in Python. PeerJ 2, e453. </p> </li> <li> <p>scipy</p> <p>P. Virtanen, R. Gommers, T.E. Oliphant et al. (2020). SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python. Nature Methods, 17, 261\u2013272.</p> </li> </ul>"},{"location":"cell_tracking_module/reference.html","title":"Cell tracking module","text":"<p>The cell tracking module allows tracking segmented cells over time. It takes segmentation masks as input, performs cell tracking and generates relabelled segmentation masks with corresponding cell tracking graphs. The cell tracking algorithm used in this module is based on the assumption that cell movement is limited between consecutive time frames. In particular, any global drift should be corrected using the registration module before performing cell tracking.</p>"},{"location":"cell_tracking_module/reference.html#input-files","title":"Input files","text":"<p>A list of multi-dimensional segmentation masks with <code>X</code>, <code>Y</code> and <code>T</code> axes (see File formats - images and masks for more information).</p> <p>To populate the list, use the Add file, Add folder and Remove selected buttons to add masks, folder (all masks inside the folder) or remove masks from the list. Alternatively, masks and folder can be dragged and dropped from an external file manager.</p> <p>When adding files or folders, only files satisfying all filters (click on <code>\u25b6</code> above the list to show filters) are added to the list. By default, only files with a filename containing <code>_vSM</code> (segmentation masks generated with the segmentation module) and ending with one of the accepted file extensions (<code>.nd2</code>, <code>.tif</code>, <code>.tiff</code>, <code>.ome.tif</code>, <code>.ome.tiff</code>) are accepted.</p>"},{"location":"cell_tracking_module/reference.html#parameters","title":"Parameters","text":"Output folder Either use each input mask folder as output folder or specify a custom output folder. To select a custom folder, either paste the path into the text box, click on the Browse button, or drag and drop a folder from an external file manager. Be careful when using a custom folder: if two input files share the same filename (from different folders), the output for both files will be written to the same output files, resulting in data corruption. Output suffix The output filename will correspond to the input filename with an additional <code>_vTG</code> suffix, optionally followed by a user defined suffix (containing only <code>a-z</code>, <code>A-Z</code>, <code>0-9</code> and <code>-</code> characters). The resulting output filenames are shown below the suffix. Min area Remove labelled regions with area (number of pixels) below this value. Max delta frame Number of previous time frames to consider when creating the cell tracking graph. See Cell tracking in the appendix for more information. Min overlap fraction Minimum overlap fraction (w.r.t labelled region area) to consider when creating edges in the cell tracking graph. See Cell tracking in the appendix for more information. Automatic cleaning If checked, perform automatic cleaning of the cell tracking graph to correct punctual defects (such as missing or mislabeled cells).  See Correction of segmentation errors in the appendix for more information. Stable overlap fraction Cell tracking graph edges corresponding to an overlap fraction below this value are considered as not stable. See Correction of segmentation errors in the appendix for more information. Max defect size (frames) Maximum size of the defect (number of frames). See Correction of segmentation errors in the appendix for more information. Max delta frame (interpolation) Number of previous and subsequent time frames to consider for mask interpolation. See Correction of segmentation errors in the appendix for more information. Min stable size (frames) Minimum number of stable time frames before and after the defect. See Correction of segmentation errors in the appendix for more information. Multi-processing Number of processes to use for coarse-grain parallelization (memory usage increases with the number of processes). This setting is only useful if there are multiple input masks, as each input mask will be assigned to its own process. Show (and edit) results in napari If checked, the resulting segmentation mask and cell tracking graph are shown in napari for visual inspection and editing. This option is disabled if there is more than one input segmentation mask. Input image Multi-dimensional image to display in napari together with segmentation mask and cell tracking graph (optional). This image should have at least <code>T</code>, <code>X</code>, and <code>Y</code> axes (with same size as the segmentation mask), and optionally <code>Z</code> and <code>C</code> axes (see File formats - images and masks for more information). To select an image, either paste the path into the text box, click on the Browse button, or drag and drop a file from an external file manager."},{"location":"cell_tracking_module/reference.html#editing-with-napari","title":"Editing with napari","text":"Figure 1: napari window with a segmentation mask overlaid on top of a bright-field image. Figure 2: napari window with the cell tracking graph associated with the segmentation mask shown in Figure 1. <p>If the \"Show (and edit) results in napari\" option is selected, the resulting relabelled segmentation mask and cell tracking graph are shown in napari, each in its own window (Figures 1 and 2).</p>"},{"location":"cell_tracking_module/reference.html#inspecting-the-segmentation-mask-and-cell-tracking-graph","title":"Inspecting the segmentation mask and cell tracking graph","text":"<p>Figure 1 shows the napari window with the segmentation mask, optionally overlaid on the image (Figure 1A). There is one layer per image channel (<code>C</code> axis) and one layer for the segmentation mask (Figure 1B). Additionally, there is one slider for the time axis (<code>T</code>, Figure 1C) and one slider the <code>Z</code> axis if the image is present and has a <code>Z</code> axis (Figure 1C).</p> <p>Figure 2 shows the napari window with the cell tracking graph. Vertices (squares) correspond to labelled regions (cells) at a given time frame. Edges correspond to overlap between labelled regions. Vertices are ordered by time along the horizontal axis (time increases from left to right).</p> <p>Both windows support panning and zooming with a mouse or touchpad. Selecting a specific <code>T</code> or <code>Z</code> axis position can be done using the respective axis slider.</p> <p>For the following, make sure that the \"Cell mask\" layer is selected (Figure 1B). When hovering over a labelled region in the segmentation mask (Figure 1D), the corresponding mask id is shown in the status bar (mask id 103, Figure 1E). Similarly, when hovering over a vertex in the cell tracking graph (Figure 2A), the corresponding time frame and mask id are shown in the status bar (time frame 30, mask id 103, Figure 2B).</p> <p>Click (left mouse button) on a labelled region in the segmentation mask to center the view on the corresponding vertex in the cell tracking graph view. Click (left mouse button) on a vertex of the cell tracking graph to center the segmentation mask view on the corresponding labelled region and time frame (<code>T</code> axis slider).</p> <p>Right-clicking on a labelled region in the segmentation mask or vertex in the cell tracking graph selects it (selected vertices are shown with a white border). Right-clicking while pressing the SHIFT key extends the selection.</p>"},{"location":"cell_tracking_module/reference.html#automatic-cleaning","title":"Automatic cleaning","text":"<p>Click on the Clean button to automatically search for punctual defects in the cell tracking graph and try to remove them by interpolating corresponding mask across neighboring time frames (Figure 1F, see Correction of segmentation errors in the appendix for more information). The following parameters are available:</p> Stable overlap fraction Cell tracking graph edges corresponding to an overlap fraction below this value are considered as not stable. Max defect size (frames) Maximum size of the defect (number of frames). Max delta frame (interpolation) Number of previous and subsequent time frames to consider for mask interpolation. Min stable size (frames) Minimum number of stable frames before and after the defect. Min area Remove labelled regions with area (number of pixels) below this value. Clean \"missing\" mask only If checked, only consider \"missing\" mask defects. Add a layer with mask modifications If checked, add a new layer that shows modifications made to the segmentation mask (red: removed regions, blue: modified regions, green: added regions)."},{"location":"cell_tracking_module/reference.html#correcting-selected-punctual-defects","title":"Correcting selected punctual defects","text":"<p>Click on the Interpolate selection button to interpolate selected labelled regions across neighboring time frames (Figure 1G, see Mask interpolation in the appendix for more information). Labelled regions are selected by clicking with the right mouse button. Right-clicking while pressing the SHIFT key extends the selection. The following parameters are available:</p> Max delta frame (interpolation) Number of previous and subsequent time frames to consider for mask interpolation. Min area Remove labelled regions with area (number of pixels) below this value. Add a layer with mask modifications If checked, add a new layer that shows modifications made to the segmentation mask (red: removed regions, blue: modified regions, green: added regions)."},{"location":"cell_tracking_module/reference.html#manual-error-correction","title":"Manual error correction","text":"<p>If interpolation is not sufficient to correct defects, it is possible to manually correct the segmentation mask by using the \"Cell mask\" layer drawing tools (Figure 1H). Note that the cell tracking graph is not updated automatically when editing the segmentation mask (this operation is too computationally intensive). To relabel the segmentation mask and recompute the cell tracking graph, click on the Relabel button (Figure 1I). </p>"},{"location":"cell_tracking_module/reference.html#relabelling","title":"Relabelling","text":"<p>The relabelling operation splits disconnected labelled regions, removes small labelled regions, recompute cell tracking graph and relabel the mask so as to have consistent mask ids in consecutive time frame (Figure 1I, see  Cell tracking in the appendix for more information).</p> <p>Relabelling should be done before saving if the \"Interpolate selection tools\" has been used, or directly after manually editing the segmentation mask.  To perform relabelling, click on the Relabel button. The following parameters are available:</p> Max delta frame Number of previous time frames to consider when creating the cell tracking graph. Min area Remove labelled regions with area (number of pixels) below this value. Min overlap fraction Minimum overlap fraction (w.r.t labelled region area) to consider when creating edges in the cell tracking graph."},{"location":"cell_tracking_module/reference.html#saving","title":"Saving","text":"<p>Click on the Save (or Relabel &amp; Save) button to save the segmentation mask and cell tracking graph. Note that when showing and editing results in napari, the segmentation mask and cell tracking graph are not saved until clicking on the Save button.</p>"},{"location":"cell_tracking_module/reference.html#closing-the-napari-windows","title":"Closing the napari windows","text":"<p>To close the napari windows, click on the Quit button (Figure 1J). Do not use the \"Close window\" option in the \"File\" menu nor the window close button, as it may crash the application. Do not use \"Exit\" option in the \"File\" menu, as it will close the full VLabApp application.</p>"},{"location":"cell_tracking_module/reference.html#output-files","title":"Output files","text":"<ul> <li>Relabelled segmentation mask (see File formats - images and masks for more information).</li> <li>Cell tracking graph (see File formats - Cell tracking graphs for more information).</li> <li>Log file (see File formats - Log files and metadata for more information).</li> </ul> <p>Output filenames are obtained by adding a <code>_vTG</code> suffix to the input filename, optionally followed by a user defined suffix. For example, with input segmentation mask</p> <pre><code>smp01_BF_vSM.ome.tif\n</code></pre> <p>the output segmentation mask, cell tracking graph and log file will have filenames:</p> <pre><code>smp01_BF_vSM_vTG.ome.tif\nsmp01_BF_vSM_vTG.graphmlz\nsmp01_BF_vSM_vTG.log\n</code></pre>"},{"location":"cell_tracking_module/reference.html#appendix-cell-tracking-method","title":"Appendix: Cell tracking method","text":""},{"location":"cell_tracking_module/reference.html#cell-tracking","title":"Cell tracking","text":""},{"location":"cell_tracking_module/reference.html#terminology","title":"Terminology","text":"<p>Terminology is illustrated in Figure 3:</p> <ul> <li>Image: original input image (e.g. bright-field image after Z-projection), below we assume it has axes T (time), Y, X and a unique channel (bright-field).</li> <li>Mask: an image with same dimension as the input image and a unique channel (segmented object label). Masks are usually generated by a segmentation algorithm (e.g. Cellpose), but can also be created manually.</li> <li>Label: An integer ID (mask id) assigned to each segmented object (in this document, labels are represented by colors).</li> <li>labelled region: sets of pixels assigned to a specific label (at a specific time frame).</li> </ul> Figure 3: Terminology."},{"location":"cell_tracking_module/reference.html#cell-tracking-graph-creation","title":"Cell tracking graph: creation","text":"<p>The cell tracking graph is created by assigning one vertex to each labelled region (one vertex per time frame) and one edge between each overlapping pair of labelled region (considering only pairs of labelled region separated by not more than \\(N_\\text{t}\\) time frames). The overlap area is stored as an edge attribute. An example of cell tracking graph obtained with \\(N_\\text{t}=2\\) is shown in Figure 4.</p> <p>Note: \\(N_\\text{t}\\) is called \"Max delta frame\" in the GUI.</p> Figure 4: Top: mask with labelled regions (color) overlaid on top of bright-field image. Bottom: cell tracking graph (obtained with N<sub>t</sub>=2). Vertex color denotes the corresponding labelled region and edge thickness denotes the overlap area. Horizontal axis corresponds to time"},{"location":"cell_tracking_module/reference.html#relabelling_1","title":"Relabelling","text":"<p>As illustrated in Figure 4, labelled region are usually obtained independently for each frame and labels (colors) do not match across time frames.  To obtain consistent labels across time, we use the following iterative relabelling approach (see Figure 5):</p> <ol> <li> <p>Labelled regions (vertices) in the first time frame (\\(t=0\\)) are    arbitrarily relabelled using consecutive integer labels \\(1\\), \\(2\\), \\(3\\),    \\(\\cdots\\) (Figure 5A).</p> </li> <li> <p>We then iterate over the remaining time frames (Figure 5B-F).</p> <ul> <li> <p>At time frame \\(t\\) (\\(t&gt;0\\)), we evaluate a \"confusion matrix\",   containing the total overlap area between each labelled region   (vertex) at time frame t and each labelled region (vertex) at   previous time frames. Note that all previous time frames (\\(t-1\\),   \\(t-2\\), \\(\\cdots\\)) have already been relabelled.   Each row of the confusion matrix corresponds to a labelled region   (vertex) in the current frame t, while each column corresponds to   a labelled region (vertex) in previous frames (\\(t-1\\), \\(t-2\\), \\(\\cdots\\),   \\(t-N_\\text{t}\\)).   The entry in the \\(i\\)-th row and \\(j\\)-th column contain sum of the   overlap areas between the labelled region (with label   corresponding to row \\(i\\)) and all labelled regions (with label   corresponding to column \\(j\\)) in the previous time frames \\(t-1\\), \\(t-2\\),   \\(\\cdots\\), \\(t-N_\\text{t}\\). It is evaluated by summing the overlap areas stored as   edge attribute for all edges connecting the vertex with label   corresponding to row \\(i\\) at time frame t to all vertices with label   corresponding to column \\(j\\) at previous time frames (dark grey   edges in Figure 5).</p> </li> <li> <p>One to one matching between labels in the current time frame   (rows) and labels in previous time frames (columns) is found   using linear sum assignment (scipy   implementation, using the opposite of the confusion matrix as   cost matrix). Labels in the current time frame are replaced by   the matching labels in previous time frames. If the confusion   matrix contains more rows than columns, some labels in current   time frame do not match any labels in previous time frames. In   this case, unmatched labels are replaced by new labels \\(m+1\\),   \\(m+2\\), \\(\\cdots\\) (with \\(m\\) the maximum label found across all   previous time frames).</p> </li> </ul> </li> </ol> <p>The resulting relabelled cell tracking graph and mask are shown in Figure 6</p> Figure 5: Iterative relabelling of the cell tracking graph. Panel A: first time frame (t=0) with corresponding vertices highlighted (white outline) and arbitrarily relabelled 1 (magenta) and 2 (green). Panels B-F: each panel corresponds to one time frame (t=1, ..., 5). Vertices corresponding to the current time frame are highlighted (white outline). Edge connecting vertices in the current time frame to vertices in previous time frames are shown in dark grey, together with the corresponding overlap area (black number). The confusion matrix is shown below the graph. Labels associated with each column/row are indicated (color). Matching between labels in the current time frame (rows) and labels in previous time frames (columns) by linear sum assignment is indicated using a bold font. Figure 6: Relabelled mask and cell tracking graph."},{"location":"cell_tracking_module/reference.html#cell-tracking-graph-cleaning","title":"Cell tracking graph: cleaning","text":"<p>The final cell tracking graph is obtained by (see Figure 7):</p> <ul> <li> <p>Removing edges corresponding to low overlap: Edges with an overlap   area smaller than a predefined fraction \\(f\\) (20% by default) of any   the labelled region area corresponding to the source or target   vertices (dashed edges in Figure 7).</p> </li> <li> <p>Adding missing edges between vertices with same label: If two   consecutive (in time) vertices with same label are not connected by   an edge, then add the missing edge between these vertices (Figure   8). This could happen after removing low overlap edges.</p> </li> <li> <p>Removing redundant edges: Intuitively, a redundant edges is an edge   enclosing another edge (light grey edges in Figure 7).  More   precisely, an edge connecting a vertex with label \\(L_1\\) at time   frame \\(t_1\\) to a vertex with label \\(L_2\\) at time frame \\(t_2\\)   (\\(t_2&gt;t_1\\)) is considered as redundant if there is at least one   other edge connecting a vertex with label \\(L_1\\) at time frame \\(t'_1\\)   to a vertex with label \\(L_2\\) at time frame \\(t'_2\\) and if \\(t'_1\\geq   t_1\\) and \\(t'_2\\leq t_2\\).</p> </li> </ul> <p>The resulting final cell tracking graph is shown in Figure 9.</p> <p>Note: The threshold \\(f\\) used to filter out edges corresponding to low overlap is called \"Min overlap fraction\" in the GUI.</p> Figure 7: Cell tracking graph cleaning. Dashed grey lines denote edges corresponding to low overlap and solid light grey lines denotes redundant edges.  Figure 8: Adding missing edges (blue). This made-up example is not related to Figure 7. Figure 9: Final cell tracking graph."},{"location":"cell_tracking_module/reference.html#correction-of-segmentation-errors","title":"Correction of segmentation errors","text":""},{"location":"cell_tracking_module/reference.html#mask-interpolation","title":"Mask interpolation","text":"<p>Cell segmentation tools (e.g. Cellpose) may occasionally produce errors (e.g. time frames 3 and 4 in Figure 10A).  When segmentation errors are punctual and surrounded (in time) by stable and error-free time frames, it is possible to correct the error using the information contained in neighboring time frames (\"interpolating\" neighboring time frames).</p> <p>To \"interpolate\" a set of labelled regions (labels 1=green and 2=red in Figure 10) over a range of time frames (t=3 and t=4 in Figure 10) using the information contained in \\(N_\\text{i}\\) neighbouring frames on each side (\\(N_\\text{i}=3\\) by default), we start by evaluating the signed distance map for each labelled region and each time frame separately (Figure 10B and 10D). Each pixel in the distance map contain pixel the signed distance from this pixel to the boundary of the labelled region, with positive distance inside the labelled region and negative distances outside.  For each selected labelled region and each selected time frame, we evaluate the median of all distance maps for the labelled region at time frames within \\(\\pm N_\\text{i}\\) of the selected time frame (Figure 10C and 10E).</p> <p>For each selected time frame, new labelled regions are obtained by assigning each pixel to the label with highest positive median distance map (Figure 10F). Pixels with negative median distance for all labelled regions are assigned to the background.</p> <p>The final mask is obtained by erasing (i.e setting to background label) selected labelled regions in selected time frames (Figure 10G) and pasting non-background pixels from the new labelled regions (Figure 10F) onto the final mask (Figure 10H).</p> <p>Note: \\(N_\\text{i}\\) is called \"Max delta frame (interpolation)\" in the GUI.</p> Figure 10: Mask correction. A: mask (overlaid on top of bright-field image) and corresponding cell tracking graph with segmentation errors in time frames 3 and 4 (made-up example). B: distance maps for labelled region 1. All pixels of the distance map at time frame 3 (missing labelled region) are set to minus infinity. C: median distance maps for labelled region 1. D and E: same as B and C but for labelled region 2. F: updated labelled regions 1 and 2 obtained by combining median distance maps. G: original mask (A) after setting labelled regions 1 and 2 to background for selected time frames 3 and 4. H: Final mask (overlaid on top of bright-field image) and corresponding cell tracking graph after merging masks F and G."},{"location":"cell_tracking_module/reference.html#automatic-correction-of-punctual-defects","title":"Automatic correction of punctual defects","text":"<p>The previous \"mask interpolation\" method can be applied to any user selected set of labelled regions and time frames. However, it may not give reasonable results if the labelled regions are not stable enough within \\(\\pm N_\\text{i}\\) time frames around the frames to be corrected.</p> <p>Intuitively, this method should work best for punctual segmentation errors (i.e. spanning only few time frames), surrounded by enough stable and error-free time frames. To automatically find this type of segmentation defects, we use the information contained in the cell tracking graph:</p> <p>Stable regions: Intuitively, a stable region of the cell tracking graph is a series of vertices in consecutive time frames (no missing time frame), all corresponding to the same mask label, each with a unique incoming and a unique outgoing edge (no branching).</p> <p>More precisely, we start by flagging all edges of the cell tracking graph as stable or not stable. An edge is defined as stable if and only if it satisfies all the following criteria (Figure 11):</p> <ul> <li>Its source and target vertices correspond to the same mask label.</li> <li>Its source and target vertices are in consecutive frames.</li> <li>Its source vertex has a unique outgoing edge (this edge) and its target vertex has a unique incoming edge (this edge).</li> <li>The overlap between labelled regions corresponding to source and target vertices is larger than a predefined fraction \\(f\\) (90% by default) of any the labelled region area corresponding to the source or target vertices.</li> </ul> <p>Examples of not stable edges are shown in Figure 11 (blue letters):</p> <ul> <li>Edge (a) is not stable because its source vertex has two outgoing edges.</li> <li>Edge (b) is not stable because the overlap between labelled regions corresponding to source and target vertices is too low.</li> <li>Edge (c) is not stable because its source and target vertices are not in consecutive frames.</li> <li>Edge (d) is not stable because its target vertex has two incoming edges.</li> <li>Edge (e) is not stable because its source and target vertices do have same label (color) and its target vertex has two incoming edges.</li> </ul> Figure 11: Examples of stable (dark grey) and not stable (light grey) edges. Vertex color denotes the corresponding label and edge thickness denotes the overlap area.  <p>Stable regions are found as the connected components of the subgraph induced by all stable edges. The size of each stable region is measured as the number of vertices in connected component (Figure 12).</p> Figure 12: Size (red text) of stable regions (dark grey edges, colored vertices). <p>Punctual defects: Candidate defects are found as the connected components of the subgraph induced by all not stable edges (ignoring trivial components of size 1).</p> <p>This initial list of candidate defects (connected components) is then filtered out to keep only punctual defects surrounded by stable regions, satisfying all the following criteria (see Figure 13):</p> <ul> <li>The time frame interval covered by the connected component is not larger than \\(N_\\text{d}+2\\) frames, where \\(N_\\text{d}\\) is a user specified maximum defect size  (2 by default). I.e. the defect is punctual.</li> <li>The set of labels associated with vertices in the first time frame of the connected component is identical to the set of labels associated with vertices in the last time frame of the connected component. I.e. the defect is stable, in the sense that the same segmented objects are present before and after the defect.</li> <li>Each vertex in first and in last time frame of the connected component belongs to a stable region (see above) of size \\(\\geq N_\\text{s}\\), where \\(N_\\text{s}\\) is a user specified minimum stable region size (3 by default). I.e. the defect is surrounded by stable regions.</li> </ul> <p>Figure 13 and 14 show exemples of candidate defects. For \\(N_\\text{d}=2\\) and \\(N_\\text{s}=3\\), the following candidate defects would be filtered out:</p> <ul> <li>Candidate defect (a): it does not have the same set of labels in first frame (blue) and in last frame (blue and green). Note that this candidate defect corresponds to a cell division (i.e. not a defect).</li> <li>Candidate defect (d): it covers 5 frames (\\(&gt;N_\\text{d}+2\\)) and the vertex in last time frame belongs to a stable region of size 2 (\\(\\lt N_\\text{s}\\)). Note that with \\(N_\\text{d}\\geq 3\\) this candidate defect would not be filtered out.</li> <li>Candidate defect (h): it does not have the same set of labels in first frame (green and purple) and in last frame (purple) and the vertex in last time frame belongs to a stable region of size 2 (\\(\\lt N_\\text{s}\\)). Note that this candidate defect corresponds to cell fusion with a labelled region missing (green, time frame 18), which cannot be corrected by this method.</li> </ul> Figure 13: Candidate defects (dark grey edges, colored vertices, identified with blue letters). Sizes of neighboring stable regions are indicated in red.  Figure 14: Labelled regions (made-up examples) corresponding to the candidate defects in Figure 13.  <p>Finally, for each remaining defect in the list, the  mask interpolation method described in the previous section is applied to the list of all labels appearing in the defect, for all time frames covered by the defect except first and last time frame (Figure 15).</p> Figure 15: Mask interpolation method applied to punctual defects (figure 13). The mask interpolation method is applied to all labels appearing in the defect and all highlighted time frames (light blue). <p>Notes:</p> <ul> <li>\\(f\\) is called \"Stable overlap fraction\" in the GUI.</li> <li>\\(N_\\text{d}\\) is called \"Max defect size\" in the GUI.</li> <li>\\(N_\\text{s}\\) is called \"Min stable size\" in the GUI.</li> <li>Ideally, the user defined parameters should satisfy \\(N_\\text{d}\\leq N_\\text{i}\\leq N_\\text{s}\\) (with \\(N_\\text{i}\\) the size of the neighboring region used for mask interpolation).</li> </ul>"},{"location":"events_selection_module/reference.html","title":"Events selection module","text":"<p>The events selection module extracts fusion or division events. It takes pairs of segmentation masks and cell tracking graphs as input, searches for fusion or division events, selects cells within a user-specified time window around each event, and saves the resulting mask and graph containing only the selected cells (Figure 1).</p> Figure 1: selection of division events. Top: original cell tracking graph. Bottom: cell tracking graph after selecting division events with 2 frames before event, 4 frames each events and allowing up to 2 missing cells."},{"location":"events_selection_module/reference.html#input-files","title":"Input files","text":"<p>A list of multi-dimensional segmentation masks with <code>X</code>, <code>Y</code> and <code>T</code> axes (see File formats - images and masks for more information) with corresponding cell tracking graphs (see File formats - Cell tracking graphs for more information).</p> <p>Corresponding mask and graph files must be in the same folder. Their filenames must share the same basename and end with the suffixes specified below the table (by default <code>&lt;basname&gt;.ome.tif</code> and .graphmlz). <p>To populate the table, use the Add file, Add folder and Remove selected buttons to add masks or graphs, folder (all masks and graphs inside the folder) or remove rows from the list. Alternatively, masks, graphs and folders can be dragged and dropped from an external file manager. Masks (resp. graphs) without a corresponding graph (resp. mask) are ignored.</p> <p>When adding files or folders, only files satisfying all filters (click on <code>\u25b6</code> above the list to show filters) are added to the list. By default, only pairs of mask and graph with a filename containing <code>_vTG</code> (segmentation masks and cell tracking graphs generated with the cell tracking module) and ending with the suffixes specified below the table (<code>.ome.tif</code> and <code>.graphmlz</code>) are accepted.</p>"},{"location":"events_selection_module/reference.html#parameters","title":"Parameters","text":"Output folder Either use each input mask/graph folder as output folder or specify a custom output folder. To select a custom folder, either paste the path into the text box, click on the Browse button, or drag and drop a folder from an external file manager. Be careful when using a custom folder: if two input files share the same filename (from different folders), the output for both files will be written to the same output file, resulting in data corruption. Output suffix The output filename will correspond to the input filename with an additional <code>_vES</code> suffix, optionally followed by a user defined suffix (containing only <code>a-z</code>, <code>A-Z</code>, <code>0-9</code> and <code>-</code> characters). The resulting output filenames are shown below the suffix. Type of events The type of events to select (<code>division</code> or <code>fusion</code>). Number of frames (before event) Number of stable frames to keep before the event. Events without the required number of stable frames before the event are not selected. Number of frames (after event) Number of stable frames to keep after the event. Events without the required number of stable frames after the event are not selected. Border filter If checked, ignore events with at least one cell of the corresponding cell track touching the border of the image. Border width (pixel) Width of the image border (in pixel). Missing cells filter If checked, ignore events with more than the specified number of missing cells (missing cells are only allowed immediately around the fusion/division event). Max missing cells Maximum number of missing cells for the missing cells filter. Multi-processing Number of processes to use for coarse-grain parallelization (memory usage increases with the number of processes). This setting is only useful if there are multiple input mask and graph, as each pair of input mask and graph will be assigned to its own process."},{"location":"events_selection_module/reference.html#output-files","title":"Output files","text":"<ul> <li>Filtered segmentation mask (see File formats - images and masks for more information).</li> <li>Filtered Cell tracking graph (see File formats - Cell tracking graphs for more information).</li> <li>Log file (see File formats - Log files and metadata for more information).</li> </ul> <p>Output filenames are obtained by adding a <code>_vES</code> suffix to the input filename, optionally followed by a user defined suffix. For example, with input segmentation mask and cell tracking graph</p> <pre><code>smp01_BF_vSM_vTG.ome.tif\nsmp01_BF_vSM_vTG.graphmlz\n</code></pre> <p>the output segmentation mask, cell tracking graph and log file will have filenames:</p> <pre><code>smp01_BF_vSM_vTG_vES.ome.tif\nsmp01_BF_vSM_vTG_vES.graphmlz\nsmp01_BF_vSM_vTG_vES.log\n</code></pre>"},{"location":"file_conversion_lossy_module/reference.html","title":"File conversion (lossy preview)","text":"<p>This module exports images and segmentation masks to small file-size preview movies (mp4) or images (jpg).  The resulting mp4 movies or jpg images are encoded using lossy compression, which results in data loss and distortion. These files should not be used for scientific applications. In addition, when converting to mp4 movie, X and Y axes are resized to the nearest multiple of 16.</p>"},{"location":"file_conversion_lossy_module/reference.html#input-files","title":"Input files","text":"<p>A list of multi-dimensional images or masks with at least <code>X</code> and <code>Y</code> axes, and optionally <code>C</code>, <code>Z</code> and <code>T</code> axes (see File formats - images and masks for more information).</p> <p>To populate the list, use the Add file, Add folder and Remove selected buttons to add images or masks, folder (all images and masks inside the folder) or remove files from the list. Alternatively, files and folder can be dragged and dropped from an external file manager.</p> <p>When adding files or folders, only files satisfying all filters (click on <code>\u25b6</code> above the list to show filters) are added to the list.  By default, only files with a filename ending with one of the accepted file extensions (<code>.nd2</code>, <code>.tif</code>, <code>.tiff</code>, <code>.ome.tif</code>, <code>.ome.tiff</code>) are accepted.</p>"},{"location":"file_conversion_lossy_module/reference.html#parameters","title":"Parameters","text":"Output folder Either use each input image or mask folder as output folder or specify a custom output folder. To select a custom folder, either paste the path into the text box, click on the Browse button, or drag and drop a folder from an external file manager. Be careful when using a custom folder: if two input files share the same filename (from different folders), the output for both files will be written to the same output file, resulting in data corruption. Output suffix The output filename will correspond to the input filename with an additional optional user defined suffix (containing only <code>a-z</code>, <code>A-Z</code>, <code>0-9</code> and <code>-</code> characters). The resulting output filenames are shown below the suffix. Input types <p>Images and segmentation masks are not processed in the same way during export. This parameters allows users to specify the type of input files:</p> <ul> <li>Auto-detect:  try to detect input file types using a heuristic.</li> <li>Images: Consider all input files as images.</li> <li>Segmentation masks: Consider all input files as images.</li> </ul> Auto-contrast If checked, adjust contrast when exporting images. Channel colors When exporting an image with multiple channels, channels are colored then merged. Click on a color to change it. Projection range and type If the input image or mask contains a <code>Z</code> axis with multiple Z sections, the chosen range of Z sections will be projected using the chosen projection type (see Z-Projection module for more information). Output format <p>Choose one of the available options:</p> <ul> <li>Auto: Convert to mp4 movie if input file has more than one time frame, to jpg otherwise.</li> <li>jpg images: convert all files to jpg images (export only the first time frame).</li> <li>mp4 movies: Convert all files to mp4 movies. This option can generate unreadable mp4 movies if the number of time frames is too low.</li> </ul> Quality mp4 movies quality. From 0 (low quality, small file-size) to 10 (high quality, large file-size). Frame per seconds number of frames per second for mp4 movies. Multi-processing Number of processes to use for coarse-grain parallelization (memory usage increases with the number of processes). This setting is only useful if there are multiple input files, as each input file will be assigned to its own process."},{"location":"file_conversion_lossy_module/reference.html#output-files","title":"Output files","text":"<ul> <li>images or segmentation masks in jpg or mp4 format (see File formats - images and masks for more information).</li> </ul> <p>Output filenames are obtained by adding the optional user defined suffix to the input filename and replacing the file extension. For example, with input segmentation mask</p> <pre><code>smp01_BF_vSM_vTG.ome.tif\n</code></pre> <p>when exporting to mp4 format, the exported segmentation mask will have filename:</p> <pre><code>smp01_BF_vSM_vTG.mp4\n</code></pre>"},{"location":"file_conversion_mask_graph_module/reference.html","title":"File conversion (masks and graphs)","text":"<p>This module exports segmentation masks and/or cell tracking graphs to various file formats, to be reused in other applications. The resulting files are not meant to be read by this application. In addition, VLabApp metadata are lost during conversion (see File formats - Log files and metadata for more information).</p>"},{"location":"file_conversion_mask_graph_module/reference.html#input-files","title":"Input files","text":"<p>A list of multi-dimensional segmentation masks with <code>X</code>, <code>Y</code> and <code>T</code> axes (see File formats - images and masks for more information) with corresponding cell tracking graphs (see File formats - Cell tracking graphs for more information).</p> <p>Corresponding mask and graph files must be in the same folder. Their filenames must share the same basename and end with the suffixes specified below the table (by default <code>&lt;basname&gt;.ome.tif</code> and .graphmlz). <p>To populate the table, use the Add file, Add folder and Remove selected buttons to add masks or graphs, folder (all masks and graphs inside the folder) or remove rows from the list. Alternatively, masks, graphs and folders can be dragged and dropped from an external file manager. Masks (resp. graphs) without a corresponding graph (resp. mask) are ignored.</p> <p>When adding files or folders, only files satisfying all filters (click on <code>\u25b6</code> above the list to show filters) are added to the list. By default, only pairs of mask and graph with a filename containing <code>_vTG</code> (segmentation masks and cell tracking graphs generated with the cell tracking module) and ending with the suffixes specified below the table (<code>.ome.tif</code> and <code>.graphmlz</code>) are accepted.</p>"},{"location":"file_conversion_mask_graph_module/reference.html#parameters","title":"Parameters","text":"Output folder Either use each input mask/graph folder as output folder or specify a custom output folder. To select a custom folder, either paste the path into the text box, click on the Browse button, or drag and drop a folder from an external file manager. Be careful when using a custom folder: if two input files share the same filename (from different folders), the output for both files will be written to the same output file, resulting in data corruption. Output suffix The output filename will correspond to the input filename with an additional optional user defined suffix (containing only <code>a-z</code>, <code>A-Z</code>, <code>0-9</code> and <code>-</code> characters). The resulting output filenames are shown below the suffix. Convert segmentation mask If checked, export input segmentation masks to ImageJ ROI set (<code>.zip</code>) format (see File formats - images and masks for more information). Convert cell tracking graph If checked, export input cell tracking graphs to the selected file format. File format <p>Export cell tracking graphs to the selected file format. The following formats are available (see File formats - Cell tracking graphs for more information):</p> <ul> <li>List of edges in tab separated value tabular format (<code>.tsv</code>).</li> <li>Graphviz dot format (<code>.dot</code>).</li> <li>GraphML format (<code>.graphml</code>).</li> </ul> Output one file per cell track If checked, generate one file per cell track (and append <code>_&lt;cell track id&gt;</code> to the output filename). Note that a large number of file can be generated when using this option. Multi-processing Number of processes to use for coarse-grain parallelization (memory usage increases with the number of processes). This setting is only useful if there are multiple input mask and graph, as each pair of input mask and graph will be assigned to its own process."},{"location":"file_conversion_mask_graph_module/reference.html#output-files","title":"Output files","text":"<ul> <li>If option \"Convert segmentation mask\" is selected, the segmentation mask in ImageJ ROI set format (see File formats - images and masks for more information).</li> <li>If option \"Convert cell tracking graph\" is selected, the cell tracking graph in the chosen file format (see File formats - Cell tracking graphs for more information).</li> </ul> <p>Output filenames are obtained by adding the optional user defined suffix to the input filename, adding a <code>_&lt;cell track id&gt;</code> suffix if the option \"Output one file per cell track\" is selected,  and replacing the file extension. For example, with input segmentation mask and cell tracking graph</p> <pre><code>smp01_BF_vSM_vTG.ome.tif\nsmp01_BF_vSM_vTG.graphmlz\n</code></pre> <p>when exporting the segmentation mask to ImageJ ROI set and the cell tracking graph to Graphviz dot format (without the \"Output one file per cell track\" option), the exported segmentation mask and cell tracking graph will have filenames:</p> <pre><code>smp01_BF_vSM_vTG.zip\nsmp01_BF_vSM_vTG.dot\n</code></pre> <p>and with the \"Output one file per cell track\" option </p> <pre><code>smp01_BF_vSM_vTG_0000.zip\nsmp01_BF_vSM_vTG_0000.dot\nsmp01_BF_vSM_vTG_0001.zip\nsmp01_BF_vSM_vTG_0001.dot\nsmp01_BF_vSM_vTG_0002.zip\nsmp01_BF_vSM_vTG_0002.dot\n...\n</code></pre>"},{"location":"file_organization_module/reference.html","title":"File organization","text":"<p>This module can be used to export (move or copy) or remove chosen file types generated with VLabApp.</p>"},{"location":"file_organization_module/reference.html#input-files","title":"Input files","text":"<p>A list of folders containing files generated with VLabApp.</p> <p>To populate the list, use the Add folder and Remove selected buttons to add folder to the list or remove folder from the list. Alternatively, folders can be dragged and dropped from an external file manager.</p> <p>When adding folders, only folders satisfying all filters (click on <code>\u25b6</code> above the list to show filters) are added to the list.  By default, all folders are accepted.</p>"},{"location":"file_organization_module/reference.html#parameters","title":"Parameters","text":"Output folder Either use each input folder as output folder or specify a custom output folder (in both cases, the ouput will be saved in a sub-folder with same basename as input folder).  To select a custom folder, either paste the path into the text box, click on the Browse button, or drag and drop a folder from an external file manager. File selection: select the type of files to export/remove. <p>Click on the Copy files or Move files button to copy or move selected files from the input folder to the output folder, or click on the Remove files button to remove selected files from the input folder.</p>"},{"location":"general/files.html","title":"File naming conventions and supported formats","text":"<p>VLabApp is based on the following workflow: for each analysis,  a copy of (or a symbolic link to) the image to analyze is placed in a working directory. This copy (or link) is used as input to VLabApp. By default, all outputs generated by VLabApp will be created into the directory containing the input file, with filenames generated by adding suffixes to the input filename.</p>"},{"location":"general/files.html#file-naming","title":"File naming","text":"<p>Each input image filename should start with a unique identifier, which is the part of the filename before the first <code>_</code>. Within a working directory, files with same unique identifier are assumed to correspond to the same image. This property is used to match files (e.g. to associate a registration matrix to an image).</p> <p>For example, all the following files have the same unique identifier (<code>smp02-s03</code>):</p> <pre><code>smp02-s03.nd2\nsmp02-s03_BF.nd2\nsmp02-s03_WL508.nd2\nsmp02-s03_BF_vRG.csv\nsmp02-s03_BF_vRG.ome.tif\n</code></pre> <p>Multidimensional images used as input can be very large. To limit the size of individual files, it is common to split an image into multiple images, each containing a unique channel. Although not mandatory, it is recommended to append a <code>_BF</code> suffix to images with a unique bright-field channel and <code>_WL&lt;w&gt;</code> to images with a unique fluorescence channel with emission wavelength <code>&lt;w&gt;</code>. For example:</p> <pre><code>smp02-s03_BF.nd2\nsmp02-s03_WL508.nd2\nsmp02-s03_WL614.nd2\n</code></pre> <p>By default, VLabApp output files are saved in the working directory containing the input file, with a filename generated by adding a suffix to input filename. The following suffixes are used in VLabApp:</p> <code>_vRG</code> <p>Output of registration module.</p> <p>Examples:</p> <ul> <li><code>smp01_vRG.csv</code></li> <li><code>smp02_vRG.ome.tif</code></li> </ul> <code>_vPR&lt;ref&gt;&lt;range&gt;&lt;proj&gt;</code> <p>Output of projection module, where <code>&lt;ref&gt;</code> is the reference Z-section (<code>b</code> for best focus or <code>f</code> for fixed range), <code>&lt;range&gt;</code> is the range of Z-sections (one integer for range around Z-section with best focus or two integers  min and max separated by a <code>-</code> for fixed Z-section range) and <code>&lt;proj&gt;</code> is the projection type (<code>none</code>, <code>max</code>, <code>min</code>, <code>mean</code>, <code>median</code> or <code>std</code>).</p> <p>Examples:</p> <ul> <li><code>smp03_vPRf3-7max.ome.tif</code> (maximum projection of all Z sections with \\(3\\le Z\\le 7\\))</li> <li><code>smp01_vRG_vPRb3mean.ome.tif</code> (mean projection of all Z sections with \\(Z\\) in the interval \\([Z_{best}-3,Z_{best}+3]\\), where \\(Z_{best}\\) is the Z section with best focus)</li> <li><code>smp04_vPRb0none.ome.tif</code> (Z-section with best focus)</li> </ul> <code>_vSM</code> <p>Output of segmentation module.</p> <p>Examples:</p> <ul> <li><code>smp02_vSM.ome.tif</code></li> <li><code>smp04_vPRb3mean_vSM.ome.tif</code></li> </ul> <code>_vTG</code> <p>Output of cell tracking module.</p> <p>Examples:</p> <ul> <li><code>smp02_vSM_vTG.ome.tif</code></li> <li><code>smp02_vSM_vTG.graphmlz</code></li> </ul> <code>_vGF</code> <p>Output of graph filtering module.</p> <p>Examples:</p> <ul> <li><code>smp04_vRG_vPRb3mean_vSM_vTG_vGF.ome.tif</code></li> <li><code>smp04_vRG_vPRb3mean_vSM_vTG_vGF.graphmlz</code></li> </ul> <code>_vES</code> <p>Output of events selection module.</p> <p>Examples:</p> <ul> <li><code>smp01_vRG_vSM_vTG_vES.ome.tif</code></li> <li><code>smp01_vRG_vSM_vTG_vES.graphmlz</code></li> </ul> <code>_vCR</code> <p>Output of image cropping module.</p> <p>Examples:</p> <ul> <li><code>smp03_vCR.ome.tif</code></li> <li><code>smp05_vRG_vPRb3mean_vSM_vTG_vTG_vCR.ome.tif</code></li> </ul> <code>_vGT</code> <p>Output of ground truth generator module.</p> <p>Examples:</p> <ul> <li><code>smp02_vGT.ome.tif</code></li> <li><code>smp04_vCR_vRG_vGT.ome.tif</code></li> </ul> <p>Notes: * All suffixes (except <code>_vPR</code>) can be followed by a user defined string using any of the <code>A-Z</code>, <code>a-z</code>, <code>0-9</code> and <code>-</code> characters.</p>"},{"location":"general/files.html#file-formats","title":"File formats","text":""},{"location":"general/files.html#images-and-masks","title":"Images and masks","text":"<p>Images and masks are multi-dimensional arrays with up to 5 dimensions. Depending on the module used, images and masks can have <code>T</code> (time), <code>C</code> (channel), <code>Z</code> (Z-section), <code>Y</code> and <code>X</code> axes.</p> <p>Masks should have the same dimension as the corresponding image (except for <code>C</code> axis) with a unique channel containing an integer mask ID (or label ID). All pixels assigned to the same segmented object (labelled region) should have the same ID, while background pixels should have ID 0.</p> <p>Input formats:</p> <ul> <li>Nikon NIS Elements format (<code>.nd2</code>).</li> <li>Open Microscopy Environment OME-TIFF format (<code>.ome.tif</code> or <code>.ome.tiff</code>).</li> <li>TIFF tagged image file format (<code>.tif</code> or <code>.tiff</code>).</li> </ul> <p>Output format:</p> <ul> <li>Open Microscopy Environment OME-TIFF format (<code>.ome.tif</code> or <code>.ome.tiff</code>) with 16-bit unsigned integer values.</li> </ul> <p>Export formats:</p> <ul> <li>MP4 video (<code>.mp4</code>).</li> <li>JPEG image (<code>.jpg</code>).</li> <li>ImageJ ROI set (<code>.zip</code>). Only for masks, with ROIs named as <code>&lt;cell track id&gt;_&lt;time frame&gt;_&lt;mask id&gt;</code>.</li> </ul>"},{"location":"general/files.html#cell-tracking-graphs","title":"Cell tracking graphs","text":"<p>Cell tracking graphs encode the time evolution of the segmentation masks, with vertices corresponding to segmented objects (usually cells) at a given time frame, and edges corresponding to overlap between segmented objects across time frames (see Cell tracking module - Appendix: Cell tracking method for more information). Connected components of the graph are called cell tracks.</p> <p>Input format:</p> <ul> <li>gzipped GraphML files created with VLabApp (<code>.graphmlz</code>).</li> </ul> <p>Output format:</p> <ul> <li>gzipped GraphML files (<code>.graphmlz</code>).</li> </ul> <p>Export formats:</p> <ul> <li> <p>List of edges (<code>.tsv</code>) in tab-separated values format, with header in first row and the following columns:</p> <ul> <li><code>id1</code>: source vertex id (correspond to the ImageJ ROI name <code>&lt;cell_track_id&gt;_&lt;frame1&gt;_&lt;mask_id1&gt;</code>).</li> <li><code>frame1</code>: source vertex time frame.</li> <li><code>mask_id1</code>: source vertex mask ID.</li> <li><code>area1</code>: source vertex area (number of pixels).</li> <li><code>id2</code>: target vertex id (correspond to the ImageJ ROI name <code>&lt;cell_track_id&gt;_&lt;frame2&gt;_&lt;mask_id2&gt;</code>).</li> <li><code>frame2</code>: target vertex time frame.</li> <li><code>mask_id2</code>: target vertex mask ID.</li> <li><code>area2</code>: target vertex area (number of pixels).</li> <li><code>overlap_area</code>: overlap between source and target vertices (number of pixels).</li> <li><code>cell_track_id</code>: cell track ID.</li> </ul> <p>Isolated vertices appear in the list with target vertex and edge properties set to <code>nan</code>.</p> </li> <li> <p>Graphviz dot format (<code>.dot</code>), with vertices named as <code>&lt;cell track id&gt;_&lt;time frame&gt;_&lt;mask id&gt;</code>. The  Graphviz <code>dot</code> tool can be used to generate a pdf file (e.g. <code>smp02_vSM_vTG.pdf</code>) with a graphical representation of the cell tracking graph (e.g. <code>smp02_vSM_vTG.dot</code>) with time flowing from top to bottom:</p> <p><code>dot -Tpdf smp02_vSM_vTG.pdf smp02_vSM_vTG.dot</code></p> </li> <li> <p>GraphML (<code>.graphml</code>), with vertices named as <code>&lt;cell track id&gt;_&lt;time frame&gt;_&lt;mask id&gt;</code>, the following vertices attributes:</p> <ul> <li><code>frame</code>: vertex time frame.</li> <li><code>mask_id</code>: vertex mask ID.</li> <li><code>area</code>: vertex area (number of pixels).</li> <li><code>cell_track</code>: cell track ID.</li> </ul> <p>and edge attribute:</p> <ul> <li><code>overlap_area</code>:  overlap between source and target vertices (number of pixels).</li> </ul> </li> </ul>"},{"location":"general/files.html#transformation-matrices-registration","title":"Transformation matrices (registration)","text":"<p>Transformation matrices are generated by the registration module and encode the shift between consecutive time frames for all time frames, as well as the range of time frames which should be taken into account when applying the transformation.</p> <p>Input/output format:</p> <ul> <li> <p>comma-separated values format (<code>.csv</code>), with optional metadata rows (starting with <code>#</code>) followed by a header and the following columns:</p> <ul> <li><code>x</code>: shift along X (pixels) axis since first kept time frame (i.e. first time frame with column <code>keep</code> set to 1).</li> <li><code>y</code>: shift along Y (pixels) axis since first kept time frame (i.e. first time frame with column <code>keep</code> set to 1).</li> <li><code>keep</code>: keep (1) or discard (0) time frame when applying the transformation.</li> <li><code>x_raw</code>: shift along X axis (pixels) since first time frame.</li> <li><code>y_raw</code>: shift along Y axis (pixels) since first time frame.</li> </ul> <p>For backward compatibility, input files with the following 8 columns are also accepted as input:</p> <ul> <li><code>timePoint</code>: time frame (1-based indexing!)</li> <li><code>align_t_x</code>: shift along X (pixels) axis since first kept time frame (i.e. first time frame with column <code>align_0_1</code> set to 1).</li> <li><code>align_t_y</code>: shift along Y (pixels) axis since first kept time frame (i.e. first time frame with column <code>align_0_1</code> set to 1).</li> <li><code>align_0_1</code>: keep (1) or discard (0) time frame when applying the transformation.</li> <li><code>raw_t_x</code>: shift along X axis (pixels) since first time frame.</li> <li><code>raw_t_y</code>: shift along Y axis (pixels) since first time frame.</li> <li><code>x</code>: image width (pixels).</li> <li><code>y</code>: image height (pixels).</li> </ul> </li> </ul>"},{"location":"general/files.html#log-files-and-metadata","title":"Log files and metadata","text":"<p>When using a module, system information (platform, python version, modules versions) as well as the operations applied along with the main parameters are  written to a log file (with same base name as the output files) and added to the metadata of the output file. The metadata from all input files are also added to the metadata of the output file, with latest metadata appearing first.</p> <p>Use the \"View metadata\" module to view metadata (see View metadata for more information).</p> <p>For example, when using the cell tracking module to  create a mask and cell tracking graph with filenames</p> <pre><code>smp01_vRG_vPRb3mean_vSM_vTG_vGF.ome.tif\nsmp01_vRG_vPRb3mean_vSM_vTG_vGF.graphmlz\n</code></pre> <p>a log file will be created with filename</p> <pre><code>smp01_vRG_vPRb3mean_vSM_vTG_vGF.log\n</code></pre> <p>and content:</p> <pre><code>2025-04-07 10:52:53,307 [INFO] System info:\n2025-04-07 10:52:53,307 [INFO] - platform: Linux-6.13.9-100.fc40.x86_64-x86_64-with-glibc2.39\n2025-04-07 10:52:53,308 [INFO] - python version: 3.11.11\n2025-04-07 10:52:53,308 [INFO] - VLabApp version: 2.3.0\n2025-04-07 10:52:53,308 [INFO] - numpy version: 1.26.4\n2025-04-07 10:52:53,308 [INFO] - opencv version: 4.11.0\n2025-04-07 10:52:53,309 [INFO] - igraph version: 0.11.8\n2025-04-07 10:52:53,309 [INFO] Input mask path: /home/jdoe/experiment1/smp01_BF_vRG_vPRb0none_vSM.ome.tif\n2025-04-07 10:52:53,453 [INFO] Creating cell tracking graph and relabelling mask: max delta frame=5, min overlap fraction=20.0%, min area=300\n2025-04-07 10:53:02,849 [INFO] Automatic cleaning: max delta frame=3, max defect size=2, min stable size=3, stable overlap fraction=90.0%, min area=300, clean missing mask only=False\n2025-04-07 10:53:15,295 [INFO] Relabelling mask and graph: max delta frame=5, min area=300, min overlap fraction=20.0%\n2025-04-07 10:53:24,137 [INFO] Saving segmentation mask to /home/jdoe/experiment1/smp01_BF_vRG_vPRb0none_vSM_vTG.ome.tif\n2025-04-07 10:53:24,207 [INFO] Saving cell tracking graph to /home/jdoe/experiment1/smp01_BF_vRG_vPRb0none_vSM_vTG.graphmlz\n</code></pre> <p>In addition, both output files</p> <pre><code>smp01_vRG_vPRb3mean_vSM_vTG_vGF.ome.tif\nsmp01_vRG_vPRb3mean_vSM_vTG_vGF.graphmlz\n</code></pre> <p>will have a full history in their metadata:</p> <pre><code>2025-04-07 10:52:53,307 (VLabApp - cell tracking module) [INFO] System info:\n2025-04-07 10:52:53,307 (VLabApp - cell tracking module) [INFO] - platform: Linux-6.13.9-100.fc40.x86_64-x86_64-with-glibc2.39\n2025-04-07 10:52:53,308 (VLabApp - cell tracking module) [INFO] - python version: 3.11.11\n2025-04-07 10:52:53,308 (VLabApp - cell tracking module) [INFO] - VLabApp version: 2.3.0\n2025-04-07 10:52:53,308 (VLabApp - cell tracking module) [INFO] - numpy version: 1.26.4\n2025-04-07 10:52:53,308 (VLabApp - cell tracking module) [INFO] - opencv version: 4.11.0\n2025-04-07 10:52:53,309 (VLabApp - cell tracking module) [INFO] - igraph version: 0.11.8\n2025-04-07 10:52:53,309 (VLabApp - cell tracking module) [INFO] Input mask path: /home/jdoe/experiment1/smp01_BF_vRG_vPRb0none_vSM.ome.tif\n2025-04-07 10:52:53,453 (VLabApp - cell tracking module) [INFO] Creating cell tracking graph and relabelling mask: max delta frame=5, min overlap fraction=20.0%, min area=300\n2025-04-07 10:53:02,849 (VLabApp - cell tracking module) [INFO] Automatic cleaning: max delta frame=3, max defect size=2, min stable size=3, stable overlap fraction=90.0%, min area=300, clean missing mask only=False\n2025-04-07 10:53:15,295 (VLabApp - cell tracking module) [INFO] Relabelling mask and graph: max delta frame=5, min area=300, min overlap fraction=20.0%\n2025-04-07 10:53:24,137 (VLabApp - cell tracking module) [INFO] Saving segmentation mask to /home/jdoe/experiment1/smp01_BF_vRG_vPRb0none_vSM_vTG.ome.tif\n2025-04-07 10:53:24,207 (VLabApp - cell tracking module) [INFO] Saving cell tracking graph to /home/jdoe/experiment1/smp01_BF_vRG_vPRb0none_vSM_vTG.graphmlz\n\n\nMetadata for /home/jdoe/experiment1/smp01_BF_vRG_vPRb0none_vSM.ome.tif:\n2025-04-07 10:52:25,116 (VLabApp - segmentation module) [INFO] System info:\n2025-04-07 10:52:25,116 (VLabApp - segmentation module) [INFO] - platform: Linux-6.13.9-100.fc40.x86_64-x86_64-with-glibc2.39\n2025-04-07 10:52:25,116 (VLabApp - segmentation module) [INFO] - python version: 3.11.11\n2025-04-07 10:52:25,116 (VLabApp - segmentation module) [INFO] - VLabApp version: 2.3.0\n2025-04-07 10:52:25,116 (VLabApp - segmentation module) [INFO] - numpy version: 1.26.4\n2025-04-07 10:52:25,116 (VLabApp - segmentation module) [INFO] - cellpose version: 3.1.0\n2025-04-07 10:52:25,116 (VLabApp - segmentation module) [INFO] - torch version: 2.6.0\n2025-04-07 10:52:25,116 (VLabApp - segmentation module) [INFO] Input image path: /home/jdoe/experiment1/smp01_BF_vRG_vPRb0none.ome.tif\n2025-04-07 10:52:25,116 (VLabApp - segmentation module) [INFO] Segmentation method: cellpose\n2025-04-07 10:52:25,116 (VLabApp - segmentation module) [INFO] Model type: User trained model\n2025-04-07 10:52:25,116 (VLabApp - segmentation module) [INFO] User trained model path: /home/jdoe/models/cyto_finetuned_projection_best\n2025-04-07 10:52:25,116 (VLabApp - segmentation module) [INFO] cellprob threshold: 0.0\n2025-04-07 10:52:25,117 (VLabApp - segmentation module) [INFO] flow threshold: 0.4\n2025-04-07 10:52:25,196 (VLabApp - segmentation module) [INFO] Preparing image to segment: selecting channel 0\n2025-04-07 10:52:25,630 (VLabApp - segmentation module) [INFO] Cellpose segmentation (diameter=75.032135)\n2025-04-07 10:52:53,214 (VLabApp - segmentation module) [INFO] Saving segmentation mask to /home/jdoe/experiment1/smp01_BF_vRG_vPRb0none_vSM.ome.tif\n\n\nMetadata for /home/jdoe/experiment1/smp01_BF_vRG_vPRb0none.ome.tif:\n2025-04-07 10:52:20,720 (VLabApp - z-projection module) [INFO] System info:\n2025-04-07 10:52:20,720 (VLabApp - z-projection module) [INFO] - platform: Linux-6.13.9-100.fc40.x86_64-x86_64-with-glibc2.39\n2025-04-07 10:52:20,720 (VLabApp - z-projection module) [INFO] - python version: 3.11.11\n2025-04-07 10:52:20,720 (VLabApp - z-projection module) [INFO] - VLabApp version: 2.3.0\n2025-04-07 10:52:20,720 (VLabApp - z-projection module) [INFO] - numpy version: 1.26.4\n2025-04-07 10:52:20,720 (VLabApp - z-projection module) [INFO] - opencv version: 4.11.0\n2025-04-07 10:52:20,720 (VLabApp - z-projection module) [INFO] Input image path: /home/jdoe/experiment1/smp01_BF_vRG.ome.tif\n2025-04-07 10:52:21,394 (VLabApp - z-projection module) [INFO] Z-Projection: projection type=mean, zrange=0 (Z section with best focus), focus method=tenengrad_var, z shift=[0, 0, 0, 0, 0, 0, 0, 0]\n2025-04-07 10:52:21,806 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 0, C: 0): mean over z in [5] (Best z=5, z shift=0)\n2025-04-07 10:52:22,230 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 1, C: 0): mean over z in [5] (Best z=5, z shift=0)\n2025-04-07 10:52:22,682 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 2, C: 0): mean over z in [5] (Best z=5, z shift=0)\n2025-04-07 10:52:23,119 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 3, C: 0): mean over z in [5] (Best z=5, z shift=0)\n2025-04-07 10:52:23,582 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 4, C: 0): mean over z in [5] (Best z=5, z shift=0)\n2025-04-07 10:52:24,035 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 5, C: 0): mean over z in [5] (Best z=5, z shift=0)\n2025-04-07 10:52:24,490 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 6, C: 0): mean over z in [5] (Best z=5, z shift=0)\n2025-04-07 10:52:24,897 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 7, C: 0): mean over z in [5] (Best z=5, z shift=0)\n2025-04-07 10:52:24,899 (VLabApp - z-projection module) [INFO] Saving projected image to /home/jdoe/experiment1/smp01_BF_vRG_vPRb0none.ome.tif\n\n\nMetadata for /home/jdoe/experiment1/smp01_BF_vRG.ome.tif:\n2025-04-07 10:51:51,982 (VLabApp - registration module) [INFO] System info:\n2025-04-07 10:51:51,982 (VLabApp - registration module) [INFO] - platform: Linux-6.13.9-100.fc40.x86_64-x86_64-with-glibc2.39\n2025-04-07 10:51:51,982 (VLabApp - registration module) [INFO] - python version: 3.11.11\n2025-04-07 10:51:51,982 (VLabApp - registration module) [INFO] - VLabApp version: 2.3.0\n2025-04-07 10:51:51,982 (VLabApp - registration module) [INFO] - numpy version: 1.26.4\n2025-04-07 10:51:51,982 (VLabApp - registration module) [INFO] - pystackreg version: 0.2.8\n2025-04-07 10:51:51,982 (VLabApp - registration module) [INFO] - opencv version: 4.11.0\n2025-04-07 10:51:51,982 (VLabApp - registration module) [INFO] - skimage version: 0.20.0\n2025-04-07 10:51:51,982 (VLabApp - registration module) [INFO] Input image path: /home/jdoe/experiment1/smp01_BF.ome.tif\n2025-04-07 10:51:51,982 (VLabApp - registration module) [INFO] Registration method: feature matching (SIFT)\n2025-04-07 10:51:52,724 (VLabApp - registration module) [INFO] Preparing image to evaluate transformation matrix: performing Z-projection\n2025-04-07 10:51:52,724 (VLabApp - registration module) [INFO] Z-Projection: projection type=std, zrange=3 (Range 3 around Z section with best focus), focus method=tenengrad_var, z shift=[0, 0, 0, 0, 0, 0, 0, 0]\n2025-04-07 10:51:53,245 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 0, C: 0): std over z in [2, 3, 4, 5, 6, 7, 8] (Best z=5, z shift=0)\n2025-04-07 10:51:53,934 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 1, C: 0): std over z in [2, 3, 4, 5, 6, 7, 8] (Best z=5, z shift=0)\n2025-04-07 10:51:54,663 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 2, C: 0): std over z in [2, 3, 4, 5, 6, 7, 8] (Best z=5, z shift=0)\n2025-04-07 10:51:55,361 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 3, C: 0): std over z in [2, 3, 4, 5, 6, 7, 8] (Best z=5, z shift=0)\n2025-04-07 10:51:55,943 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 4, C: 0): std over z in [2, 3, 4, 5, 6, 7, 8] (Best z=5, z shift=0)\n2025-04-07 10:51:56,498 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 5, C: 0): std over z in [2, 3, 4, 5, 6, 7, 8] (Best z=5, z shift=0)\n2025-04-07 10:51:57,064 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 6, C: 0): std over z in [2, 3, 4, 5, 6, 7, 8] (Best z=5, z shift=0)\n2025-04-07 10:51:57,626 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 7, C: 0): std over z in [2, 3, 4, 5, 6, 7, 8] (Best z=5, z shift=0)\n2025-04-07 10:51:57,755 (VLabApp - registration module) [INFO] Preparing image to evaluate transformation matrix: selecting channel 0\n2025-04-07 10:51:57,755 (VLabApp - registration module) [INFO] Evaluating transformation matrix with feature matching (SIFT)\n2025-04-07 10:52:18,523 (VLabApp - registration module) [INFO] Saving transformation matrix to /home/jdoe/experiment1/smp01_BF_vRG.csv\n2025-04-07 10:52:18,526 (VLabApp - registration module) [INFO] Transforming image\n2025-04-07 10:52:18,729 (VLabApp - registration module) [INFO] Cropping image\n2025-04-07 10:52:18,729 (VLabApp - registration module) [INFO] Saving transformed image to /home/jdoe/experiment1/smp01_BF_vRG.ome.tif\n</code></pre>"},{"location":"general/installation.html","title":"Installation","text":"<ol> <li> <p>Install Conda</p> <p>If Conda is not already installed, download and install Miniconda or Anaconda from https://www.anaconda.com/download/.</p> </li> <li> <p>Download VLabApp</p> <p>Go to the latest release page and download the Source code archive (<code>.zip</code> or <code>.tar.gz</code>). Extract the archive, then open a terminal or anaconda powershell prompt (Windows) and navigate to the extracted folder. </p> </li> <li> <p>Create a new conda environment</p> <p>If an older <code>venv_VLabApp</code> environment exists, remove it with <code>conda env remove --name venv_VLabApp</code>.</p> <p>Run the following command to create a new environment</p> <pre><code>conda create --name venv_VLabApp python=3.11.11\n</code></pre> </li> <li> <p>Activate the environment</p> <p>After the environment is created, activate it</p> <pre><code>conda activate venv_VLabApp\n</code></pre> </li> <li> <p>Install dependencies</p> <p>Use <code>pip</code> to install dependencies listed in the <code>requirements.txt</code> file</p> <pre><code>pip install -r requirements.txt\n</code></pre> <p>Windows: CUDA support</p> <p>To enable GPU acceleration on Windows with an NVIDIA GPU, a CUDA-enabled build of PyTorch must be installed. Use one of the following commands instead, selecting the CUDA version suited to your system:</p> <ul> <li> <p>For CUDA 12.9:</p> <pre><code>pip install -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu129\n</code></pre> </li> <li> <p>For CUDA 12.8:</p> <pre><code>pip install -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu128\n</code></pre> </li> <li> <p>For CUDA 12.6:</p> <pre><code>pip install -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu126\n</code></pre> </li> </ul> <p>More information is available in the official PyTorch documentation https://pytorch.org/get-started/locally/</p> </li> <li> <p>Start the application</p> <p>In the <code>venv_VLabApp</code> environment, start the application with</p> <pre><code>python master.py\n</code></pre> </li> </ol>"},{"location":"general/installation.html#on-linux","title":"On Linux","text":"<p>Be careful on the limit of files that you are allowed to open. The fine-grain parallelization of the segmentation module could open up to 1000 files per process.  Adjust the maximum number of open file descriptors to 10000 with <code>ulimit</code> before starting VLabApp with:</p> <pre><code>ulimit -n 10000\npython3 master.py\n</code></pre> <p>This would be enough for a 10 CPU machine.</p>"},{"location":"general/plugins.html","title":"Plugins","text":"<p>To add a new Hello World plugin:</p> <ol> <li> <p>Create a new folder named <code>hello_world/</code> inside the <code>plugins/</code> folder, which is located in the VLabApp installation directory.</p> </li> <li> <p>In the <code>hello_world/</code> folder, create a file named <code>__init__.py</code>. Your folder structure should look like:</p> <pre><code>VLabApp/\n\u251c\u2500\u2500 plugins/\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 hello_world/\n\u2502\u00a0\u00a0  \u00a0\u00a0 \u2514\u2500\u2500 __init__.py\n\u2502\n</code></pre> </li> <li> <p>Add the following python code to <code>__init__.py</code>:</p> <pre><code>from PyQt5.QtWidgets import QWidget, QVBoxLayout, QLabel\n\n# Name of the plugin (used in the left panel of the GUI)\nNAME = 'Hello World!'\n\n# The widget (shown in the right panel of the GUI)\nclass Widget(QWidget):\n    def __init__(self, pipeline_layout=False):\n        super().__init__()\n        layout = QVBoxLayout()\n        self.setLayout(layout)\n        label = QLabel('Hello world!')\n        layout.addWidget(label)\n</code></pre> <p>Notes:</p> <ul> <li>The <code>__init__.py</code> file must define a variable <code>NAME</code>, whose value will be displayed in the left panel of VLabApp as the plugin name.</li> <li>It must also defined a class named <code>Widget</code>, that is a subclass of <code>QWidget</code>. It will appear in the right panel when clicking on the plugin name in the left panel.</li> </ul> </li> <li> <p>Start VLabApp. The new \"Hello World!\" plugin should appear in the left panel inside the \"Plugins\" section.</p> </li> </ol>"},{"location":"general/tutorial.html","title":"Tutorial","text":""},{"location":"general/tutorial.html#preparation","title":"Preparation","text":"<p>If not done yet, install VLabApp (see Installation for more information).</p> <p>Create a working directory <code>example1/</code> and copy the sample bright-field image (doc/data/smp01_BF.ome.tif) and fluorescent image (doc/data/smp01_WL450.ome.tif) from the VLabApp sub-folder <code>doc/data/</code> to the working directory <code>example1/</code>:</p> <p>Open a terminal or anaconda powershell prompt (Windows) and navigate to the VLabApp folder. Activate the conda environment</p> <pre><code>conda activate venv_VLabApp\n</code></pre> <p>and start VLabApp with</p> <pre><code>python master.py\n</code></pre>"},{"location":"general/tutorial.html#vlabapp-interface","title":"VLabApp interface","text":"<p>VLabApp is a collection of independent modules. Each module loads selected input files, processes them, and saves the resulting output files in the same folder (unless otherwise specified).</p> <p>The interface is composed of two panels: a list of modules on the left (Figure 1A), and a panel that provides settings and controls for the selected module on the right (Figure 1B).</p> Figure 1: VLabApp user interface."},{"location":"general/tutorial.html#viewing-images-and-metadata","title":"Viewing images and metadata","text":"<p>Select \"View metadata\" from the left panel (Figure 1C). The right panel will display the settings for this module. All modules begin with a \"Documentation\" section, which can be expanded by clicking \"[show more]\". This section contains basic information about the module and the expected input files. For additional information, click the \"Documentation\" link at the end of the section. This will open the VLabApp documentation in a web browser.</p> <p>Click the  Browse button to open a file selection dialog. Navigate to the <code>example1/</code> folder and select the bright-field image <code>smp01_BF.ome.tif</code>. Alternatively, paste the path to the image into the text box, or drag and drop the image from an external file manager into the text box.</p> <p>The image metadata will be displayed in the lower part of the panel:</p> <pre><code>Dimensions: (T: 30, Z: 7, Y: 635, X: 651)\nChannel names: \"BF\"\nPhysical pixel sizes: (X: 0.065015720421583 \u03bcm, Y: 0.065015720421583 \u03bcm, Z: 1.0 \u03bcm)\nData type: uint8\n</code></pre> <p>Note that this module focuses on metadata generated by VLabApp. Only a limited subset of other image metadata is shown.</p> <p>This image consists of a time series of 30 frames (<code>T</code> axis), each containing 7 Z-sections (<code>Z</code> axis). Each Z-section is a 651x635 pixels 2D image (<code>X</code> and <code>Y</code> axes). The image has a single channel named \"BF\". Each pixel has size 0.065 \u03bcm in both the X and Y directions and the Z-sections are separated by 1 \u03bcm. The data are stored as 8-bit unsigned integers.</p> <p>Repeat the operation with the second sample image <code>smp01_WL450.ome.tif</code> (either adjust the text, use the Browse button, or drop the file on the text box). The metadata will update to:</p> <pre><code>Dimensions: (T: 30, Y: 635, X: 651)\nChannel names: \"2-BFP\"\nPhysical pixel sizes: (X: 0.065015720421583 \u03bcm, Y: 0.065015720421583 \u03bcm, Z: 1.0 \u03bcm)\nData type: uint8\n</code></pre> <p>This image has the same number of time frames and the same X and Y dimensions as the bright-field image, but it does not have multiple Z-sections. It has a single channel named \"2-BFP\". The physical pixel sizes and data type are the same as those of the bright-field image. See View metadata for more information on this module.</p> <p>To view images using napari, select \"View image, mask and graph\" from the left panel (Figure 1D). In the \"Image\" field, select the bright-field image <code>smp01_BF.ome.tif</code> (use the Browse button, or drag and drop the file from an external file manager), then click the Open napari button.</p> <p>A napari window opens with the bright-field image displayed in the \"Image [BF]\" layer. The mouse or touchpad can be used to pan and zoom the view (<code>X</code> and <code>Y</code> axes). The <code>T</code> and <code>Z</code> sliders below the image allow navigation through time frames and Z-sections, respectively.</p> <p>Layer-specific controls are available in the \"Layer controls\" panel (top left). Image contrast can be adjusted using the \"contrast limits\" slider, and the colormap can be changed using the corresponding dropdown. See https://napari.org/stable/howtos/layers/image.html for more information on the napari user interface.</p> <p>The <code>Z</code> slider below the image allows navigation through Z-sections. Note how the Z-sections transition from out of focus (Z=0) to best focus (Z=3) and back to out of focus (Z=6).</p> <p>Set the <code>Z</code> slider to the section with best focus (Z=3), and navigate through time frames using the <code>T</code> slider. Note how the cells drift to the left.</p> <p>Close the napari window using the window close button or the \"Close window\" option in the \"File\" menu. Do not use the \"Exit\" option in the \"File\" menu, as it will close the full VLabApp application.</p> <p>Repeat the operation with the second sample image <code>smp01_WL450.ome.tif</code> (either adjust the text, use the Browse button, or drop the file on the text box).</p> <p>See View image, mask and graph for more information on this module.</p>"},{"location":"general/tutorial.html#registration","title":"Registration","text":"<p>To correct the drift observed in the previous section, select the \"Registration\" module in the left panel.</p> <p>Add the bright-field image to the list of input files by clicking the Add files button below the list. In the file selection dialog, navigate to the <code>example1/</code> folder and select the bright-field image <code>smp01_BF.ome.tif</code>. To add all images from a folder, click the Add folder button and select a folder. To remove an image from the list, select the image and click Remove selected. It is also possible to drag and drop images or folders from an external file manager into the list. By default, only files with a filename containing <code>_BF</code> (image with a unique bright-field channel), not containing <code>_vRG</code> (to avoid already registered images), and ending with one of the supported file extensions (<code>.nd2</code>, <code>.tif</code>, <code>.tiff</code>, <code>.ome.tif</code>, <code>.ome.tiff</code>) are accepted. To modify this behavior, click on <code>\u25b6</code> above the list and adjust the filters.</p> <p>By default, the output files (transformation matrix and registered image) are saved in the same folder as the input image. To save in another folder, check the \"Use custom folder\" checkbox in the \"Output\" panel and specify an output folder in the text box (use the Browse button, or drag and drop a folder from an external file manager). Output filenames will correspond to the input filename with an additional <code>_vRG</code> suffix, optionally followed by a user defined suffix. The resulting output filenames are shown below the suffix. For this tutorial, we will keep the default \"Use input folder\" and leave the user suffix empty.</p> <p>The \"Options\" panel contains several options specific to the this module (see Registration module - Registration for more information). Keep all settings to their default value, except the \"Co-align files with the same unique identifier\" checkbox which should be checked. With this option, all files with same unique identifier (starting with <code>smp01</code>) will be also transformed using the transformation matrix evaluated on the input image.</p> <p>Click Submit to start the registration module.</p> <p>A status dialog will open, displaying one row per input file (in this example, only one row). When the registration process completes, the column Status will indicate the outcome (\"Success\" or \"Failed\"). In case of an error, hover the cursor over the cell marked as \"Failed\" to view the error message as a tooltip.</p> <p>Click OK to close the dialog.</p> <p>The <code>example1/</code> folder should contain the following files:</p> <pre><code>example1/\n\u251c\u2500\u2500 smp01_BF.ome.tif\n\u251c\u2500\u2500 smp01_BF_vRG.csv\n\u251c\u2500\u2500 smp01_BF_vRG.log\n\u251c\u2500\u2500 smp01_BF_vRG.ome.tif\n\u251c\u2500\u2500 smp01_WL450.ome.tif\n\u251c\u2500\u2500 smp01_WL450_vRG.log\n\u2514\u2500\u2500 smp01_WL450_vRG.ome.tif\n</code></pre> <p>In addition to the original input files (<code>smp01_BF.ome.tif</code> and <code>smp01_WL450.ome.tif</code>), the folder contains several files with the suffix <code>_vRG</code>, indicating that they were generated by the registration module:</p> <ul> <li><code>smp01_BF_vRG.csv</code> contains the transformation parameters (shifts) detected from the image <code>smp01_BF.ome.tif</code></li> <li><code>smp01_BF_vRG.ome.tif</code> is the registered bright-field image, generated by applying the transformation matrix <code>smp01_BF_vRG.csv</code> to the original bright-field image <code>smp01_BF.ome.tif</code>.</li> <li><code>smp01_BF_vRG.log</code> contains a log of the operations performed to generate both <code>smp01_BF_vRG.csv</code> and <code>smp01_BF_vRG.ome.tif</code>.</li> <li><code>smp01_WL450_vRG.ome.tif</code> is the registered fluorescent image, generated by applying the same transformation matrix <code>smp01_BF_vRG.csv</code> to the original fluorescent image <code>smp01_WL450.ome.tif</code>. This output was produced because co-alignment was requested for images sharing the same unique identifier (<code>smp01</code>).</li> <li><code>smp01_WL450_vRG.log</code> contains a log of the operations performed to generate <code>smp01_WL450_vRG.ome.tif</code>.</li> </ul> <p>All operations performed to generate output files are recorded in the corresponding log file. For example, consider the log file <code>smp01_BF_vRG.log</code>, which documents the steps taken to produce <code>smp01_BF_vRG.csv</code> and <code>smp01_BF_vRG.ome.tif</code>:</p> <pre><code>2025-06-16 10:59:45,292 [INFO] System info:\n2025-06-16 10:59:45,292 [INFO] - platform: Linux-6.14.9-200.fc41.x86_64-x86_64-with-glibc2.40\n2025-06-16 10:59:45,292 [INFO] - python version: 3.11.11\n2025-06-16 10:59:45,292 [INFO] - VLabApp version: 2.3.0\n2025-06-16 10:59:45,292 [INFO] - numpy version: 1.26.4\n2025-06-16 10:59:45,292 [INFO] - pystackreg version: 0.2.8\n2025-06-16 10:59:45,292 [INFO] - opencv version: 4.11.0\n2025-06-16 10:59:45,292 [INFO] - skimage version: 0.20.0\n2025-06-16 10:59:45,292 [INFO] Input image path: /home/jdoe/example1/smp01_BF.ome.tif\n2025-06-16 10:59:45,292 [INFO] Registration method: feature matching (SIFT)\n2025-06-16 10:59:45,469 [INFO] Preparing image to evaluate transformation matrix: performing Z-projection\n2025-06-16 10:59:45,469 [INFO] Z-Projection: projection type=std, zrange=3 (Range 3 around Z section with best focus), focus method=tenengrad_var, z shift=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n2025-06-16 10:59:45,508 [INFO] Z-Projection (F: 0, T: 0, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,540 [INFO] Z-Projection (F: 0, T: 1, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,574 [INFO] Z-Projection (F: 0, T: 2, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,607 [INFO] Z-Projection (F: 0, T: 3, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,638 [INFO] Z-Projection (F: 0, T: 4, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,669 [INFO] Z-Projection (F: 0, T: 5, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,701 [INFO] Z-Projection (F: 0, T: 6, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,729 [INFO] Z-Projection (F: 0, T: 7, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,758 [INFO] Z-Projection (F: 0, T: 8, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,787 [INFO] Z-Projection (F: 0, T: 9, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,816 [INFO] Z-Projection (F: 0, T: 10, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,844 [INFO] Z-Projection (F: 0, T: 11, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,870 [INFO] Z-Projection (F: 0, T: 12, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,895 [INFO] Z-Projection (F: 0, T: 13, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,922 [INFO] Z-Projection (F: 0, T: 14, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,948 [INFO] Z-Projection (F: 0, T: 15, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,973 [INFO] Z-Projection (F: 0, T: 16, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,000 [INFO] Z-Projection (F: 0, T: 17, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,025 [INFO] Z-Projection (F: 0, T: 18, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,051 [INFO] Z-Projection (F: 0, T: 19, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,077 [INFO] Z-Projection (F: 0, T: 20, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,102 [INFO] Z-Projection (F: 0, T: 21, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,127 [INFO] Z-Projection (F: 0, T: 22, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,151 [INFO] Z-Projection (F: 0, T: 23, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,175 [INFO] Z-Projection (F: 0, T: 24, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,201 [INFO] Z-Projection (F: 0, T: 25, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,225 [INFO] Z-Projection (F: 0, T: 26, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,249 [INFO] Z-Projection (F: 0, T: 27, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,273 [INFO] Z-Projection (F: 0, T: 28, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,301 [INFO] Z-Projection (F: 0, T: 29, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,311 [INFO] Preparing image to evaluate transformation matrix: selecting channel 0\n2025-06-16 10:59:46,312 [INFO] Evaluating transformation matrix with feature matching (SIFT)\n2025-06-16 10:59:51,447 [INFO] Saving transformation matrix to /home/jdoe/example1/smp01_BF_vRG.csv\n2025-06-16 10:59:51,448 [INFO] Transforming image\n2025-06-16 10:59:51,474 [INFO] Cropping image\n2025-06-16 10:59:51,474 [INFO] Saving transformed image to /home/jdoe/example1/smp01_BF_vRG.ome.tif\n</code></pre> <p>It starts with system information, followed by a list of the operations performed to generate the transformation matrix and the registered image: input file, registration method, projection of the Z-stack, channel selection, method used to evaluate the transformation matrix and output file.</p> <p>The same information is also stored in the metadata of both output files: <code>smp01_BF_vRG.csv</code> and <code>smp01_BF_vRG.ome.tif</code>. To view the metadata, select \"View metadata\" from the left panel and add <code>smp01_BF_vRG.csv</code> to the \"File\" text box. Repeat the process with <code>smp01_BF_vRG.ome.tif</code> to inspect its metadata as well.</p> <p>Similarly, the log file <code>smp01_WL450_vRG.log</code> documents the steps taken to produce <code>smp01_WL450_vRG.ome.tif</code>:</p> <pre><code>2025-06-16 10:59:52,002 [INFO] System info:\n2025-06-16 10:59:52,002 [INFO] - platform: Linux-6.14.9-200.fc41.x86_64-x86_64-with-glibc2.40\n2025-06-16 10:59:52,002 [INFO] - python version: 3.11.11\n2025-06-16 10:59:52,002 [INFO] - VLabApp version: 2.3.0\n2025-06-16 10:59:52,002 [INFO] - numpy version: 1.26.4\n2025-06-16 10:59:52,002 [INFO] - pystackreg version: 0.2.8\n2025-06-16 10:59:52,002 [INFO] - opencv version: 4.11.0\n2025-06-16 10:59:52,002 [INFO] - skimage version: 0.20.0\n2025-06-16 10:59:52,002 [INFO] Input image path: /home/jdoe/example1/smp01_WL450.ome.tif\n2025-06-16 10:59:52,002 [INFO] Input transformation matrix path: /home/jdoe/example1/smp01_BF_vRG.csv\n2025-06-16 10:59:52,062 [INFO] Transforming image\n2025-06-16 10:59:52,065 [INFO] Cropping image\n2025-06-16 10:59:52,065 [INFO] Saving transformed image to /home/jdoe/example1/smp01_WL450_vRG.ome.tif\n</code></pre> <p>Note that the information is limited to the transformation of the image <code>smp01_WL450.ome.tif</code>: input files (image and transformation matrix), transformation, cropping and output file.</p> <p>This information is also stored in the metadata of <code>smp01_WL450_vRG.ome.tif</code>, which can be viewed using the \"View metadata\" module in the left panel:</p> <pre><code>Dimensions: (T: 30, Y: 603, X: 572)\nChannel names: \"2-BFP\"\nPhysical pixel sizes: (X: 0.065015720421583 \u03bcm, Y: 0.065015720421583 \u03bcm, Z: 1.0 \u03bcm)\nData type: uint8\n\n---------------------------------------------\n\n2025-06-16 10:59:52,002 (VLabApp - registration module) [INFO] System info:\n2025-06-16 10:59:52,002 (VLabApp - registration module) [INFO] - platform: Linux-6.14.9-200.fc41.x86_64-x86_64-with-glibc2.40\n2025-06-16 10:59:52,002 (VLabApp - registration module) [INFO] - python version: 3.11.11\n2025-06-16 10:59:52,002 (VLabApp - registration module) [INFO] - VLabApp version: 2.3.0\n2025-06-16 10:59:52,002 (VLabApp - registration module) [INFO] - numpy version: 1.26.4\n2025-06-16 10:59:52,002 (VLabApp - registration module) [INFO] - pystackreg version: 0.2.8\n2025-06-16 10:59:52,002 (VLabApp - registration module) [INFO] - opencv version: 4.11.0\n2025-06-16 10:59:52,002 (VLabApp - registration module) [INFO] - skimage version: 0.20.0\n2025-06-16 10:59:52,002 (VLabApp - registration module) [INFO] Input image path: /home/jdoe/example1/smp01_WL450.ome.tif\n2025-06-16 10:59:52,002 (VLabApp - registration module) [INFO] Input transformation matrix path: /home/jdoe/example1/smp01_BF_vRG.csv\n2025-06-16 10:59:52,062 (VLabApp - registration module) [INFO] Transforming image\n2025-06-16 10:59:52,065 (VLabApp - registration module) [INFO] Cropping image\n2025-06-16 10:59:52,065 (VLabApp - registration module) [INFO] Saving transformed image to /home/jdoe/example1/smp01_WL450_vRG.ome.tif\n\n\nMetadata for matrix /home/jdoe/example1/smp01_BF_vRG.csv:\n2025-06-16 10:59:45,292 (VLabApp - registration module) [INFO] System info:\n2025-06-16 10:59:45,292 (VLabApp - registration module) [INFO] - platform: Linux-6.14.9-200.fc41.x86_64-x86_64-with-glibc2.40\n2025-06-16 10:59:45,292 (VLabApp - registration module) [INFO] - python version: 3.11.11\n2025-06-16 10:59:45,292 (VLabApp - registration module) [INFO] - VLabApp version: 2.3.0\n2025-06-16 10:59:45,292 (VLabApp - registration module) [INFO] - numpy version: 1.26.4\n2025-06-16 10:59:45,292 (VLabApp - registration module) [INFO] - pystackreg version: 0.2.8\n2025-06-16 10:59:45,292 (VLabApp - registration module) [INFO] - opencv version: 4.11.0\n2025-06-16 10:59:45,292 (VLabApp - registration module) [INFO] - skimage version: 0.20.0\n2025-06-16 10:59:45,292 (VLabApp - registration module) [INFO] Input image path: /home/jdoe/example1/smp01_BF.ome.tif\n2025-06-16 10:59:45,292 (VLabApp - registration module) [INFO] Registration method: feature matching (SIFT)\n2025-06-16 10:59:45,469 (VLabApp - registration module) [INFO] Preparing image to evaluate transformation matrix: performing Z-projection\n2025-06-16 10:59:45,469 (VLabApp - registration module) [INFO] Z-Projection: projection type=std, zrange=3 (Range 3 around Z section with best focus), focus method=tenengrad_var, z shift=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n2025-06-16 10:59:45,508 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 0, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,540 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 1, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,574 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 2, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,607 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 3, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,638 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 4, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,669 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 5, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,701 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 6, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,729 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 7, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,758 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 8, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,787 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 9, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,816 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 10, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,844 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 11, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,870 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 12, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,895 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 13, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,922 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 14, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,948 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 15, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:45,973 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 16, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,000 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 17, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,025 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 18, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,051 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 19, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,077 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 20, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,102 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 21, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,127 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 22, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,151 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 23, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,175 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 24, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,201 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 25, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,225 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 26, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,249 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 27, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,273 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 28, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,301 (VLabApp - registration module) [INFO] Z-Projection (F: 0, T: 29, C: 0): std over z in [0, 1, 2, 3, 4, 5, 6] (Best z=3, z shift=0)\n2025-06-16 10:59:46,311 (VLabApp - registration module) [INFO] Preparing image to evaluate transformation matrix: selecting channel 0\n2025-06-16 10:59:46,312 (VLabApp - registration module) [INFO] Evaluating transformation matrix with feature matching (SIFT)\n2025-06-16 10:59:51,447 (VLabApp - registration module) [INFO] Saving transformation matrix to /home/jdoe/example1/smp01_BF_vRG.csv\n</code></pre> <p>It begins with a limited subset of important image metadata (dimension, channel names, physical pixel sizes and data type), followed by the metadata generated by VLabApp. The first block contains the operations used to transform the image (the information contained in the log file <code>smp01_BF_vRG.log</code>). Subsequent blocks contain a recursive listing of the metadata from all input files (in this example: only the transformation matrix <code>smp01_BF_vRG.csv</code>). By recursively storing the metadata of all input files, each file contains a complete record of how it was generated. </p> <p>It is recommended to verify the results of the registration.  This can be done in two ways:</p> <ol> <li> <p>Use the \"View image, mask and graph\" module in the left panel to view the registered image <code>smp01_BF_vRG.ome.tif</code> (add <code>smp01_BF_vRG.ome.tif</code> to the \"Image\" text box and click Open napari). If the registration procedure was successful, the cells should be globally stable when navigating through time frames with the <code>T</code> slider. Note:</p> <ul> <li>Although the <code>Z</code> axis was projected to evaluate the transformation matrix, the registered image still includes all seven Z-sections from the input image.</li> <li>The <code>X</code> and <code>Y</code> axes of the registered image have been cropped to the common region shared by all time frames.</li> </ul> </li> <li> <p>Select \"View registration matrix\" from the left panel. This module requires two input files: the original image (<code>smp01_BF.ome.tif</code>), which was used as input for the registration module and the corresponding transformation matrix (<code>smp01_BF_vRG.csv</code>). Use the Browse button in the \"Registration matrix\" box to select the registration matrix <code>smp01_BF_vRG.csv</code>. Alternatively, paste the path in the text box or drag and drop the file from an external file manager. The \"Image (before registration)\" field should automatically populate with the original bright-field image <code>smp01_BF.ome.tif</code> (if not, use the Browse button to select the image). Click Open napari. If the registration procedure was successful, the cells should be globally stable when navigating through time frames with the <code>T</code> slider (see View registration matrix for more information on this module).</p> </li> </ol> <p>In case of registration failure, select an alternative registration method (\"Registration method\" dropdown list in the Registration module settings) and rerun the registration. If this still fails, it is possible to manually correct the transformation using manual editing (see next section).</p>"},{"location":"general/tutorial.html#registration-manual-editing","title":"Registration - manual editing","text":"<p>For more information on this module, see Registration module - Editing (manual).</p> <p>From the left panel, select \"Editing (manual)\" under the \"Registration\" group. This module requires the same two input files as the \"View registration matrix\" module: the original image (<code>smp01_BF.ome.tif</code>), which was used as input for the registration module and the corresponding transformation matrix (<code>smp01_BF_vRG.csv</code>). Use the Browse button in the \"Registration matrix\" box to select the registration matrix <code>smp01_BF_vRG.csv</code>. Alternatively, paste the path in the text box or drag and drop the file from an external file manager. The \"Image (before registration)\" field should automatically populate with the original bright-field image <code>smp01_BF.ome.tif</code> (if not, use the Browse button to select the image). Click Submit.</p> Figure 2: Manually editing the registration matrix with napari <p>The unregistered image opens in  napari (Figure 2A), with a graphical representation of the transformation matrix in the lower part of the window (Figure 2B) showing x (red) and y (blue) coordinates of the image offset (vertical axis) as a function of time (horizontal axis). </p> <p>The transformation matrix is also represented by a green control point (Figure 2C) overlaid on the image (layer \"Alignment points\"). The position of the control point is transformed using the transformation matrix (i.e. it should ideally follow the cells in the image). If needed, the transformation matrix can be modified by adjusting the position of the control point at the current time frame (selected with the Z slider), from first to current time frame, or from current time frame to last (the desired behavior can be selected in the right part of the screen, Figure 2D). To move the control point for the selected range of frame, make sure the layer \"Alignment points\" is selected (Figure 2E), then click at the desired position while pressing the CTRL key (or CMD key with Mac OS X).</p> <p>It is also possible to adjust the range of time frames to use for the transformation by modifying the \"From\" and \"To\" fields (Figure 2F). Registered images generated using a transformation matrix with a limited range of time frames will include only those specified time frames. As an example, set the range of time frame \"From\" 2 \"to\" 27 (Figure 2F).</p> <p>To save the transformation matrix (and overwrite the original transformation matrix file), click on the Save button (Figure 2G), then close the napari window using the window close button or the \"Close window\" option in the \"File\" menu. Do not use the \"Exit\" option in the \"File\" menu, as it will close the full VLabApp application. To ignore the modifications, close the napari window without saving.</p> <p>Check the metadata of the transformation matrix <code>smp01_BF_vRG.csv</code>. A new block has been added at the beginning, indicating that manual editing was performed.</p> <p>When the transformation matrix is modified using this module, previously registered images are not updated. The registered images must be regenerated by applying the updated transformation matrix to the original images <code>smp01_BF.ome.tif</code> and <code>smp01_WL450.ome.tif</code>, using the \"Alignment\" module (see next section).</p>"},{"location":"general/tutorial.html#registration-alignment","title":"Registration - Alignment","text":"<p>This module applies existing transformation matrices (created with the registration module) to input images to generate registered images. For more information on this module, see Registration module - Alignment.</p> <p>From the left panel, select the \"Alignment\" module under the \"Registration\" group.</p> <p>Add the original bright-field image (<code>smp01_BF.ome.tif</code>) and fluorescent image (<code>smp01_WL450.ome.tif</code>) by clicking the Add files button below the list. For each image, the corresponding transformation matrix will be added automatically by searching for transformation matrix files with same unique identifier (<code>smp01</code>) in the same folder as the image. To add all images from a folder, click the Add folder button and select a folder. To remove an image from the list, select the image and click Remove selected. It is also possible to drag and drop images or folders from an external file manager into the list. By default, only files not containing <code>_vRG</code> (to avoid already registered images), and ending with one of the supported file extensions (<code>.nd2</code>, <code>.tif</code>, <code>.tiff</code>, <code>.ome.tif</code>, <code>.ome.tiff</code>) are accepted. To modify this behavior, click on <code>\u25b6</code> above the list and adjust the filters.</p> <p>Click Submit to start aligning the images.</p> <p>This operation will replace the registered images and corresponding log files:</p> <pre><code>smp01_BF_vRG.log\nsmp01_BF_vRG.ome.tif\nsmp01_WL450_vRG.log\nsmp01_WL450_vRG.ome.tif\n</code></pre> <p>Check the metadata of the registered images using \"View metadata\" module, or inspect the registered images using \"View image, mask and graph\" module. Both images have a <code>T</code> axis of size 26, which corresponds to the range of time frames (from 2 to 27) specified when updating the transformation matrix.</p>"},{"location":"general/tutorial.html#z-projection","title":"Z-projection","text":"<p>The Z-projection module removes the <code>Z</code> axis from an image by projecting a user-selected subset of Z-sections and saves the resulting image. For more information on this module, see Z-Projection module.</p> <p>Note that this step is optional, as the modules that require a Z-projected image as input (the registration and segmentation modules) can perform the projection on the fly. However, using the Z-projection module to generate a projected image can still be useful for instance, to visually inspect the projection result or to save the projected image for subsequent reuse.</p> <p>Select \"Z-Projection\" from the left panel. Add the registered bright-field image (<code>smp01_BF_vRG.ome.tif</code>) to the list of input files (use the Add files button below the list or drag and drop the files from an external file manager).</p> <p>By default, the output file (Z-projected image) is saved in the same folder as the input image. To save in another folder, check the \"Use custom folder\" checkbox in the \"Output\" panel and specify an output folder in the text box (use the Browse button, or drag and drop a folder from an external file manager). For this tutorial, we will keep the default \"Use input folder\". The output filename will correspond to the input filename with an additional <code>_vPR&lt;ref&gt;&lt;range&gt;&lt;proj&gt;</code> suffix, where <code>&lt;ref&gt;</code> is the reference Z-section (<code>b</code> for best focus or <code>f</code> for fixed range), <code>&lt;range&gt;</code> is the range of Z-sections (one integer for range around Z-section with best focus or two integers  min and max separated by a <code>-</code> for fixed Z-section range) and <code>&lt;proj&gt;</code> is the projection type (<code>none</code>, <code>max</code>, <code>min</code>, <code>mean</code>, <code>median</code> or <code>std</code>).  The resulting output filename is shown below the suffix. It is not possible to set a user defined suffix in this module.</p> <p>The \"Options\" panel contains several options specific to the this module (see Z-Projection module for more information). Set the \"Projection range\" to \"Z section with best focus\" to keep only the Z section with best focus.</p> <p>Click Submit to start the Z-projection module.</p> <p>A status dialog will open, displaying one row per input file (in this example, only one row). When the registration process completes, the column Status will indicate the outcome (\"Success\" or \"Failed\"). In case of an error, hover the cursor over the cell marked as \"Failed\" to view the error message as a tooltip. Click OK to close the dialog.</p> <p>The <code>example1/</code> folder should contain two new files with the suffix <code>_vPRb0none</code>, indicating that they were generated by the Z-projection module (<code>_vPR</code>), using only the Z-section with best focus (<code>b0none</code>):</p> <ul> <li><code>smp01_BF_vRG_vPRb0none.ome.tif</code> is the Z-projected registered bright-field image, generated by applying the selected Z-projection to <code>smp01_BF_vRG.ome.tif</code>.</li> <li><code>smp01_BF_vRG_vPRb0none.log</code> contains a log of the operations performed to generate <code>smp01_BF_vRG_vPRb0none.ome.tif</code>.</li> </ul> <p>Check the metadata of the Z-projected image <code>smp01_BF_vRG_vPRb0none.ome.tif</code> using the \"View metadata\" module. Since the <code>Z</code> axis is removed by the Z-projection, the Z-projected image should only have <code>T</code>, <code>Y</code> and <code>X</code> axes:</p> <pre><code>Dimensions: (T: 26, Y: 603, X: 573)\n</code></pre> <p>The first block of metadata contains the operations performed by the Z-projection module:</p> <pre><code>2025-06-27 15:45:57,015 (VLabApp - z-projection module) [INFO] System info:\n2025-06-27 15:45:57,015 (VLabApp - z-projection module) [INFO] - platform: Linux-6.15.3-100.fc41.x86_64-x86_64-with-glibc2.40\n2025-06-27 15:45:57,015 (VLabApp - z-projection module) [INFO] - python version: 3.11.11\n2025-06-27 15:45:57,015 (VLabApp - z-projection module) [INFO] - VLabApp version: 2.3.0\n2025-06-27 15:45:57,015 (VLabApp - z-projection module) [INFO] - numpy version: 1.26.4\n2025-06-27 15:45:57,015 (VLabApp - z-projection module) [INFO] - opencv version: 4.11.0\n2025-06-27 15:45:57,015 (VLabApp - z-projection module) [INFO] Input image path: /home/jdoe/example1/smp01_BF_vRG.ome.tif\n2025-06-27 15:45:57,154 (VLabApp - z-projection module) [INFO] Z-Projection: projection type=mean, zrange=0 (Z section with best focus), focus method=tenengrad_var, z shift=[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n2025-06-27 15:45:57,183 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 0, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,211 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 1, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,238 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 2, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,265 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 3, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,290 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 4, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,317 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 5, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,342 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 6, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,367 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 7, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,392 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 8, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,416 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 9, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,441 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 10, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,465 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 11, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,490 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 12, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,515 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 13, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,540 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 14, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,567 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 15, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,594 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 16, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,624 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 17, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,655 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 18, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,683 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 19, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,708 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 20, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,733 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 21, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,759 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 22, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,785 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 23, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,810 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 24, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,835 (VLabApp - z-projection module) [INFO] Z-Projection (F: 0, T: 25, C: 0): mean over z in [3] (Best z=3, z shift=0)\n2025-06-27 15:45:57,835 (VLabApp - z-projection module) [INFO] Saving projected image to /home/jdoe/example1/smp01_BF_vRG_vPRb0none.ome.tif\n</code></pre> <p>For each time frame (<code>T</code>), the projection operation  (<code>mean over z in [3]</code>) and the estimated Z section with best focus (<code>Best z=3</code>) are indicated. Note that when the projection is performed over a single Z-section (here z=3), computing the mean is equivalent to selecting that Z-section directly.</p> <p>Next, inspect the Z-projected image <code>smp01_BF_vRG_vPRb0none.ome.tif</code> using \"View image, mask and graph\" module. Use the <code>T</code> slider below the image to verify that each time frame corresponds to the Z-section with best focus. If needed, the original image <code>smp01_BF_vRG.ome.tif</code> can also be opened the \"View image, mask and graph\" module to verify which Z-section corresponds to the best focus.</p> <p>The algorithm used to detect the Z-section with best focus occasionally produce incorrect results. If this occurs, an alternative approach is to set the \"Projection range\" option to \"Fixed range\" and manually specify the range of Z-sections to project. In this example, set \"From\" to 3 and \"To\" to 3 to select only the Z-section corresponding to best focus (Z=3).</p>"},{"location":"general/tutorial.html#segmentation","title":"Segmentation","text":"<p>To segment the registered bright-field image, select the \"Registration\" module in the left panel. Add the registered bright-field image (<code>smp01_BF_vRG.ome.tif</code>) to the list of input files (use the Add files button below the list or drag and drop the files from an external file manager). By default, only files with a filename containing <code>_BF</code> (image with a unique bright-field channel) and ending with one of the supported file extensions (<code>.nd2</code>, <code>.tif</code>, <code>.tiff</code>, <code>.ome.tif</code>, <code>.ome.tiff</code>) are accepted. To modify this behavior, click on <code>\u25b6</code> above the list and adjust the filters.</p> <p>By default, the output file (segmentation mask) is saved in the same folder as the input image. To save in another folder, check the \"Use custom folder\" checkbox in the \"Output\" panel and specify an output folder in the text box (use the Browse button, or drag and drop a folder from an external file manager). Output filename will correspond to the input filename with an additional <code>_vSM</code> suffix, optionally followed by a user defined suffix. The resulting output filename is shown below the suffix. For this tutorial, keep the default \"Use input folder\" and leave the user suffix empty.</p> <p>The \"Options\" panel contains several options specific to the this module (see Segmentation module for more information). In the segmentation section, ensure that \"Method\" is set to \"cellpose\" and \"Model type\" is set to \"User trained model\". In the \"Model\" field, select the file doc/data/cellpose_BF_yeast located in the VLabApp sub-folder <code>doc/data/</code> (use the Browse button, or drag and drop the file from an external file manager into the text box). This model was obtained by fine-tuning the cellpose cyto2 model on bright-field images of yeast cells (using Z-section with best focus). In no \"User trained model\" is available, it is possible to use one of the built-in cellpose models, such as the \"cyto3\" generalist model.</p> <p>Since the input file (<code>smp01_BF_vRG.ome.tif</code>) contains a <code>Z</code> axis, it is necessary to specify how to project it before performing segmentation. It is recommended to use the same Z-projection as the one applied to the images used for training the segmentation model. If this information is available, a reasonable alternative is to use the \"Z section with best focus\". Set the \"Projection range\" to \"Z section with best focus\" to keep only the Z section with best focus. Click Submit to start the segmentation module.</p> <p>The <code>example1/</code> folder should contain two new files with the suffix <code>_vSM</code>, indicating that they were generated by the segmentation module</p> <ul> <li><code>smp01_BF_vRG_vSM.ome.tif</code> is the segmentation mask.</li> <li><code>smp01_BF_vRG_vSM.log</code> contains a log of the operations performed to generate <code>smp01_BF_vRG_vSM.ome.tif</code>.</li> </ul> <p>To inspect the segmentation mask, select the \"View image, mask and graph\" module in the left panel and add the segmentation mask <code>smp01_BF_vRG_vSM.ome.tif</code> to the \"Segmentation mask\" box  (use the Browse button, or drag and drop from an external file manager). The \"Image\" field should automatically populate with the registered bright-field image <code>smp01_BF_vRG.ome.tif</code> (if not, use the Browse button to select the image). Click Open napari. See View image, mask and graph for more information on this module.</p> <p>A napari window opens with the bright-field image displayed in the \"Image [BF]\" layer and the segmentation mask in the \"Cell mask\" layer (See https://napari.org/stable/howtos/layers/image.html and https://napari.org/stable/howtos/layers/labels.html for more information on the napari user interface for image and labels layers respectively). Note that editing tools are intentionally disabled to prevent modifications of the segmentation mask.  The <code>Z</code> slider controls the displayed Z-section of the bright-field image (the segmentation mask has no <code>Z</code> axis and is not affected by this setting). Use the <code>T</code> slider below the image to navigate through time frames and inspect the segmentation mask. Note how the segmented cell labels (colors) are not consistent over time. Because segmentation is performed independently for each time frames, there is no guarantee that the same cell will receive the same label (color) in consecutive time frames.</p>"},{"location":"graph_filtering_module/reference.html","title":"Graph filtering module","text":"<p>The graph filtering module allows users to select a subset of cell tracks (connected components of the cell tracking graph) using various criteria and save the resulting filtered segmentation mask and cell tracking graph for further processing.</p>"},{"location":"graph_filtering_module/reference.html#input-files","title":"Input files","text":"<p>A list of multi-dimensional segmentation masks with <code>X</code>, <code>Y</code> and <code>T</code> axes (see File formats - images and masks for more information) with corresponding cell tracking graphs (see File formats - Cell tracking graphs for more information).</p> <p>Corresponding mask and graph files must be in the same folder. Their filenames must share the same basename and end with the suffixes specified below the table (by default <code>&lt;basname&gt;.ome.tif</code> and .graphmlz). <p>To populate the table, use the Add file, Add folder and Remove selected buttons to add masks or graphs, folder (all masks and graphs inside the folder) or remove rows from the list. Alternatively, masks, graphs and folders can be dragged and dropped from an external file manager. Masks (resp. graphs) without a corresponding graph (resp. mask) are ignored.</p> <p>When adding files or folders, only files satisfying all filters (click on <code>\u25b6</code> above the list to show filters) are added to the list. By default, only pairs of mask and graph with a filename containing <code>_vTG</code> (segmentation masks and cell tracking graphs generated with the cell tracking module) and ending with the suffixes specified below the table (<code>.ome.tif</code> and <code>.graphmlz</code>) are accepted.</p>"},{"location":"graph_filtering_module/reference.html#parameters","title":"Parameters","text":"Output folder Either use each input mask/graph folder as output folder or specify a custom output folder. To select a custom folder, either paste the path into the text box, click on the Browse button, or drag and drop a folder from an external file manager. Be careful when using a custom folder: if two input files share the same filename (from different folders), the output for both files will be written to the same output file, resulting in data corruption. Output suffix The output filename will correspond to the input filename with an additional <code>_vGF</code> suffix, optionally followed by a user defined suffix (containing only <code>a-z</code>, <code>A-Z</code>, <code>0-9</code> and <code>-</code> characters). The resulting output filenames are shown below the suffix. Filters The output files will contain only cell tracks that satisfy all selected filters. For a description of the available filters, please refer to the descriptions in the GUI. Multi-processing Number of processes to use for coarse-grain parallelization (memory usage increases with the number of processes). This setting is only useful if there are multiple input mask and graph, as each pair of input mask and graph will be assigned to its own process. Show (and edit) results in napari If checked, the resulting segmentation mask and cell tracking graph are shown in napari for visual inspection and editing. This option is disabled if there is more than one pair of segmentation mask and cell tracking graph. Input image Multi-dimensional image to display in napari together with segmentation mask (optional). This image should have at least <code>T</code>, <code>X</code>, and <code>Y</code> axes (with same size as the segmentation mask), and optionally <code>Z</code> and <code>C</code> axes (see File formats - images and masks for more information). To select an image, either paste the path into the text box, click on the Browse button, or drag and drop a file from an external file manager."},{"location":"graph_filtering_module/reference.html#editing-with-napari","title":"Editing with napari","text":"Figure 1: napari window with a filtered segmentation mask overlaid on top of a bright-field image. <p>If the \"Show (and edit) results in napari\" option is selected, the filtered mask is shown in napari, optionally overlaid on the image (Figure 1A). There is one layer per image channel (<code>C</code> axis), one layer for the original unfiltered segmentation mask (layer \"Cell mask\", hidden by default) and one layer for the filtered segmentation mask (layer \"Selected cell mask\", Figure 1B). Additionally, there is one slider for the time axis (<code>T</code>, Figure 1C) and one slider the <code>Z</code> axis if the image is present and has a <code>Z</code> axis (Figure 1C).</p> <p>To filter cell tracks, check the chosen filters in the right panel (Figure 1D), then click on the Filter button (Figure 1E) to update the filtered segmentation mask (layer \"Selected cell mask\"). Note that filters are always applied to the original unfiltered segmentation mask.</p> <p>Click on the Save (or Filter &amp; Save) button to save the filtered segmentation mask and cell tracking graph. Note that when showing and editing results in napari, the segmentation mask and cell tracking graph are not saved until clicking on the Save button.</p>"},{"location":"graph_filtering_module/reference.html#output-files","title":"Output files","text":"<ul> <li>Filtered segmentation mask (see File formats - images and masks for more information).</li> <li>Filtered Cell tracking graph (see File formats - Cell tracking graphs for more information).</li> <li>Log file (see File formats - Log files and metadata for more information).</li> </ul> <p>Output filenames are obtained by adding a <code>_vGF</code> suffix to the input filename, optionally followed by a user defined suffix. For example, with input segmentation mask and cell tracking graph</p> <pre><code>smp01_BF_vSM_vTG.ome.tif\nsmp01_BF_vSM_vTG.graphmlz\n</code></pre> <p>the output segmentation mask, cell tracking graph and log file will have filenames:</p> <pre><code>smp01_BF_vSM_vTG_vGF.ome.tif\nsmp01_BF_vSM_vTG_vGF.graphmlz\nsmp01_BF_vSM_vTG_vGF.log\n</code></pre>"},{"location":"ground_truth_generator_module/reference.html","title":"Ground truth generator","text":"<p>Segmentation accuracy can be significantly improved by fine-tuning an existing model, rather than relying on a generalist model such as the built-in Cellpose cyto3 model.</p> <p>This module allows users to prepare a ground truth segmentation mask for an image and export it in a format that can be directly used as a training set by Cellpose to fine-tune a segmentation model.</p>"},{"location":"ground_truth_generator_module/reference.html#input-files","title":"Input files","text":"Bright-field image A multi-dimensional bright-field image with at least <code>X</code> and <code>Y</code> axes, and optionally <code>Z</code> and <code>T</code> axes (see File formats - images and masks for more information). Fluorescent image with cell marker 1 A multi-dimensional fluorescent image of a cell marker with same dimension as the bright-field image (see File formats - images and masks for more information). This field is optional if a segmentation mask is specified. Fluorescent image with cell marker 2 A multi-dimensional fluorescent image of a cell marker with  with same dimension as the bright-field image (see File formats - images and masks for more information). This field is optional. Segmentation mask A multi-dimensional segmentation mask at least <code>X</code> and <code>Y</code> axes, and optionally a <code>T</code> axis (see File formats - images and masks for more information). It must have same <code>X</code>, <code>Y</code> and <code>T</code> axes sizes as the bright-field image. This field is optional if a fluorescent image with cell marker is specified. Click on <code>\u25b6</code> to show. <p>To select a file, either paste the path into the text box, click on the Browse button, or drag and drop a file from an external file manager.</p> <p>When filling any of the input fields, other empty fields will be populated by a best guess (files in the same directory, assuming bright-field image filename ends with <code>_BF</code> and fluorescent images filenames end with <code>_WL&lt;w&gt;</code>, where <code>&lt;w&gt;</code> is the emission wavelength). Edit a field to erase the proposed files (e.g. type any character then erase it).</p>"},{"location":"ground_truth_generator_module/reference.html#parameters","title":"Parameters","text":"Output folder Either use input bright-field image folder as output folder or specify a custom output folder. To select a custom folder, either paste the path into the text box, click on the Browse button, or drag and drop a folder from an external file manager. Output suffix The output filename will correspond to the input filename with an additional <code>_vGT</code> suffix, optionally followed by a user defined suffix (containing only <code>a-z</code>, <code>A-Z</code>, <code>0-9</code> and <code>-</code> characters). The resulting output filenames are shown below the suffix."},{"location":"ground_truth_generator_module/reference.html#usage","title":"Usage","text":"Figure 1: preparing ground truth annotations with napari. <p>The bright-field image opens in a napari window (Figure 1A), together with the fluorescent images and segmentation mask (if specified), with one layer per input file (Figure 1B) and one slider per bright-field image axis (Figure 1C).</p> <p>The general workflow is as follows:</p> Segmentation (Figure 1D) If at least one fluorescent image with cell marker is specified, a \"Segmentation\" section will be available in the right panel.   Click on the Segment button to generate a segmentation mask using thresholding based segmentation on the fluorescent images. The resulting segmentation mask is stored in the layer \"Mask\" (any existing content in this layer will be overwritten).    Note that fluorescent images are first normalized to the contrast limits of their respective layers, then merged (mean value) before performing segmentation. Edit mask (Figure 1E) The segmentation mask \u2014 whether obtained through thresholding based segmentation of fluorescent image(s) or by loading an existing segmentation mask \u2014 can be manually edited using the \"Mask\" layer drawing tools (Figure 1F). Be sure to check all time frames (<code>T</code> axis slider). Export (Figure 1G) <p>If the bright-field image does not include a <code>Z</code> axis, click on the Export button to export the bright-field image and segmentation mask in a format that can be directly used as a training set by Cellpose (i.e., one pair of 2D bright-field image and segmentation mask in <code>.tif</code> format per time frame).</p> <p>If the bright-field image includes a <code>Z</code> axis, additional parameters appear in the \"Export\" section (Figure 1H, dashed rectangle). The <code>Z</code> axis of the bright-field image will be projected using the selected range of Z-sections and projection type (see Z-Projection module for more information). For best results, models fine-tuned with a specific Z projection settings should only be applied to images generated using the same Z projection settings. Note that a model fine-tuned on images obtained by projecting a range of Z-sections around the Z-section with best focus tends to be less sensitive to slightly out-of-focus images, compared to models fine-tuned using only one Z section with best focus.</p> <p>Additionally, incorporating slightly out-of-focus bright-field images into the training set can improve the robustness of the resulting model. To introduce such variability, set the \"Max Z shift\" parameter to a non-zero value. This will randomly shift the Z-section range by up to \\(\\pm\\)\"Max Z shift\" before projection.</p> <p>Finally, click on the Export button to export the Z-projected (optionally randomly shifted) bright-field image and segmentation mask in a format that can be directly used as a training set by Cellpose (i.e., one pair of 2D bright-field image and segmentation mask in <code>.tif</code> format per time frame).</p> Save mask (Figure 1I) To save the edited segmentation mask in the same format as segmentation masks created with the segmentation module, click on the Save mask button. Saved segmentation masks can be later loaded in this module to be manually edited and exported as Cellpose training-set."},{"location":"ground_truth_generator_module/reference.html#output-files","title":"Output files","text":"<p>If Save mask was clicked: * Segmentation mask (see File formats - images and masks for more information). * Log file (see File formats - Log files and metadata for more information).</p> <p>If Export was clicked: * One pair of 2D  (<code>X</code> and <code>Y</code> axis) bright-field image and segmentation mask in TIFF tagged image format <code>.tif</code> per time frame in the input bright-field image. * Log file (see File formats - Log files and metadata for more information).</p> <p>Output filenames are obtained by adding a <code>_vGT</code> suffix to the input bright-field image filename, optionally followed by a user defined suffix. For example, with input bright-field image</p> <pre><code>smp01_BF.nd2\n</code></pre> <p>the saved segmentation mask and log file will have filenames:</p> <pre><code>smp01_BF_vGT.ome.tif\nsmp01_BF_vGT.log\n</code></pre> <p>Exported files are saved in a folder with name obtained by adding a <code>_vGT</code> suffix to the input bright-field image filename, optionally followed by a user defined suffix and, if the bright-field image includes a <code>Z</code> axis, by a Z-projection suffix (see Z-projection module - Output files for more information). The filenames of exported images are obtained by taking the output directory name, followed by a <code>_vT&lt;time frame&gt;</code> suffix if the input image has multiple time frames. The segmentation mask has an additional <code>_masks</code> suffix. For example, with input bright-field image</p> <pre><code>smp01_BF.nd2\n</code></pre> <p>and with mean projection over a range of 3 Z-sections around the Z-section with best focus, the export folder will be named:</p> <pre><code>smp01_BF_vGT_vPRb3mean/\n</code></pre> <p>If the input image includes a <code>T</code> axis, bright-field images be exported to</p> <pre><code>smp01_BF_vGT_vPRb3mean/smp01_BF_vGT_vPRb3mean_vT000.tif\nsmp01_BF_vGT_vPRb3mean/smp01_BF_vGT_vPRb3mean_vT001.tif\nsmp01_BF_vGT_vPRb3mean/smp01_BF_vGT_vPRb3mean_vT002.tif\nsmp01_BF_vGT_vPRb3mean/smp01_BF_vGT_vPRb3mean_vT003.tif\n...\n</code></pre> <p>and segmentation masks to</p> <pre><code>smp01_BF_vGT_vPRb3mean/smp01_BF_vGT_vPRb3mean_vT000_masks.tif\nsmp01_BF_vGT_vPRb3mean/smp01_BF_vGT_vPRb3mean_vT001_masks.tif\nsmp01_BF_vGT_vPRb3mean/smp01_BF_vGT_vPRb3mean_vT002_masks.tif\nsmp01_BF_vGT_vPRb3mean/smp01_BF_vGT_vPRb3mean_vT003_masks.tif\n...\n</code></pre> <p>and the log file will have filename</p> <pre><code>smp01_BF_vGT_vPRb3mean/smp01_BF_vGT_vPRb3mean.log\n</code></pre>"},{"location":"image_cropping_module/reference.html","title":"Image cropping","text":"<p>With this module multi-dimensional images or segmentation mask can be cropped along any axis.</p>"},{"location":"image_cropping_module/reference.html#input-files","title":"Input files","text":"<p>A list of multi-dimensional images or masks with any combination of <code>X</code>, <code>Y</code>, <code>Z</code>, <code>C</code>, and <code>T</code> axes (see File formats - images and masks for more information).</p> <p>To populate the list, use the Add file, Add folder and Remove selected buttons to add images or masks, folder (all images and masks inside the folder) or remove files from the list. Alternatively, files and folder can be dragged and dropped from an external file manager.</p> <p>When adding files or folders, only files satisfying all filters (click on <code>\u25b6</code> above the list to show filters) are added to the list.  By default, only files with a filename not containing <code>_vCR</code> (to avoid already cropped images), and ending with one of the accepted file extensions (<code>.nd2</code>, <code>.tif</code>, <code>.tiff</code>, <code>.ome.tif</code>, <code>.ome.tiff</code>) are accepted.</p>"},{"location":"image_cropping_module/reference.html#parameters","title":"Parameters","text":"Output folder Either use each input images or mask folder as output folder or specify a custom output folder. To select a custom folder, either paste the path into the text box, click on the Browse button, or drag and drop a folder from an external file manager. Be careful when using a custom folder: if two input files share the same filename (from different folders), the output for both files will be written to the same output file, resulting in data corruption. Output suffix The output filename will correspond to the input filename with an additional <code>_vCR</code> suffix, optionally followed by a user defined suffix (containing only <code>a-z</code>, <code>A-Z</code>, <code>0-9</code> and <code>-</code> characters). The resulting output filenames are shown below the suffix. Crop T axis If checked, crop <code>T</code> axis to the [From, To] range (0-based indexing). The cropping range is inclusive: when cropping from 2 to 10, all <code>T</code> axis indices 2, 3, ..., 10 are kept.  From Minimum <code>T</code> axis index to keep. It will generate an error if larger than maximum <code>T</code> axis index. To Maximum <code>T</code> axis index to keep. If larger than maximum <code>T</code> axis index, it will be set to the maximum <code>T</code> axis index. <p>Parameters for the other axes behave in the same way.</p> Load settings from an image... Click on the Load settings from an image... button to select a previously cropped image or mask, and set the cropping parameters using the information from its metadata. Show (and edit) results in napari If checked, the resulting image or segmentation mask is shown in napari where it can be interactively cropped. This option is disabled if there is more than one input segmentation mask."},{"location":"image_cropping_module/reference.html#interactive-cropping-with-napari","title":"Interactive cropping with napari","text":"Figure 1: Interactive cropping with napari. <p>If the \"Show (and edit) results in napari\" option is selected, the cropped image or mask is shown in napari. There is one layer for the cropped image, overlaid on top of the input image layer (Figure 1B). The input image layer is colored in red to highlight the cropped regions.</p> <p>If the image includes a <code>T</code>, <code>C</code>, or <code>Z</code> axis, a separate slider is provided for each axis (Figure 1C). Note that, unlike in other modules, image channels (<code>C</code> axis) are controlled via a slider rather than being displayed as distinct layers.</p> <p>To crop an axis, activate the corresponding checkbox and adjust the parameters using the \"From\" and \"To\" boxes or the range slider (Figure 1D).</p> <p>Alternatively, click on the Load settings from image... button (Figure 1E) to select a previously cropped image or mask, and set the cropping parameters using the information from its metadata.</p> <p>Notes:</p> <ul> <li>It is not possible to select a range of size one (e.g., <code>T</code> axis from 5 to 5) using the range slider; use the \"From\" and \"To\" boxes instead.</li> <li>The displayed image will be entirely red if any of the  <code>T</code>, <code>C</code>, or <code>Z</code> sliders are positioned outside of their cropping range (i.e., all displayed pixels will be removed from the cropped image). For example, is the <code>Z</code> axis slider (Figure 1C) is set to position 2 with a <code>Z</code> axis cropped from 4 to 6.</li> </ul> <p>To save the cropped image or mask, click on the Save cropped image (Figure 1F). Note that when showing and editing results in napari, the cropped image or mask is not saved until clicking on the Save cropped image button.</p>"},{"location":"image_cropping_module/reference.html#output-files","title":"Output files","text":"<ul> <li>Cropped image or mask (see File formats - images and masks for more information).</li> <li>Log file (see File formats - Log files and metadata for more information).</li> </ul> <p>Output filenames are obtained by adding a <code>_vCR</code> suffix to the input filename, optionally followed by a user defined suffix. For example, with input image</p> <pre><code>smp01_BF.nd2\n</code></pre> <p>the output cropped image and log file will have filenames:</p> <pre><code>smp01_BF_vCR.ome.tif\nsmp01_BF_vCR.log\n</code></pre>"},{"location":"pipeline_module/reference.html","title":"Pipeline module","text":"<p>With the pipeline module, the main modules can be combined to create a linear pipeline. </p>"},{"location":"pipeline_module/reference.html#creating-a-pipeline","title":"Creating a pipeline","text":"Figure 1: Drag and drop modules to create a pipeline. <p>To create a pipeline, click on the + button (Figure 1A) to open the list of available modules (Figure 1B), then drag and drop chosen modules (Figure 1C) to the pipeline's list of modules (Figure 1D). Each module requires a specific set of input files types (annotated circles on the left) and generates a set of output files (annotated circles on the right). When dropping a module, all its input file types must be available from the previous module's output file types. In addition, at most one registration module can be added to the module. For example (Figure 2), the \"Segmentation\" module can be placed after the \"Registration\" module, the \"Registration (alignment)\" module (with image output) or the \"Z-Projection\" module all these modules generate an image file type which is required as input for the \"Registration\" module. However, the \"Segmentation\" module cannot be placed after \"Registration (alignment)\" module (with mask output), the \"Segmentation\" module, the \"Cell tracking\" module, the \"Graph filtering\" module or the \"Events selection\" module since none of these modules generate the required image file type.</p> Figure 2: Available modules. Input and output file types are indicated with annotated circles on the left and right, respectively."},{"location":"pipeline_module/reference.html#parameters","title":"Parameters","text":"<p>Select a module to reveal its parameters below the list of modules. For a description of the available parameters, please see the corresponding module documentation.</p> <p>To access general pipeline settings, select the \"Setting\" module (Figure 1E). Note that these setting will be applied to all modules in the pipeline. The following parameters will be available below the list of modules:</p> Input files List of input files. This option depends on the first module placed after the \"Settings module\". Please see the corresponding module documentation for more information. Output folder Either use each input mask/graph folder as output folder or specify a custom output folder. To select a custom folder, either paste the path into the text box, click on the Browse button, or drag and drop a folder from an external file manager. Be careful when using a custom folder: if two input files share the same filename (from different folders), the output for both files will be written to the same output file, resulting in data corruption. Use GPU Use a GPU if available. Currently, GPU can only be used in the Segmentation module. Using this option prevents from using CPU parallelization (both coarse grain or fine grain) for the Segmentation module, although coarse grain parallelization can still be used for other modules. Number of processes Number of processes to use. Use coarse grain parallelization If checked, each input file is assigned to its own process. Coarse grain parallelization should be used when there are more input files than processes and enough memory (memory usage increases with the number of processes). If neither this option nor the \"Use GPU\" option are selected, fine grained parallelization will be used for the Segmentation module."},{"location":"pipeline_module/reference.html#starting-the-pipeline","title":"Starting the pipeline","text":"<p>Click on the Submit button at the bottom of page to start the pipeline. A progress dialog will open, showing the evolution of the computations. To abort the pipeline, click on the Abort button. Note that this will cancel the remaining operations, but the currently running operations will continue until completion. </p>"},{"location":"pipeline_module/reference.html#saving-and-loading-a-pipeline","title":"Saving and loading a pipeline","text":"<p>Use the Load settings... and Save settings... buttons (Figure 1F) to load or save all settings of the pipeline. </p>"},{"location":"registration_module/reference.html","title":"Registration module","text":""},{"location":"registration_module/reference.html#registration","title":"Registration","text":"<p>The registration module estimates the shift between consecutive time frames. The resulting transformation matrix is applied to the input image to generate a registered image.</p>"},{"location":"registration_module/reference.html#input-files","title":"Input files","text":"<p>A list of multi-dimensional images with at least <code>T</code>, <code>X</code>, and <code>Y</code> axes, and optionally <code>Z</code> and <code>C</code> axes (see File formats - images and masks for more information).</p> <p>To populate the list, use the Add file, Add folder and Remove selected buttons to add images, folder (all images inside the folder) or remove images from the list. Alternatively, images and folder can be dragged and dropped from an external file manager.</p> <p>When adding files or folders, only files satisfying all filters (click on <code>\u25b6</code> above the list to show filters) are added to the list. By default, only files with a filename containing <code>_BF</code> (image with a unique bright-field channel), not containing <code>_vRG</code> (to avoid already registered images), and ending with one of the accepted file extensions (<code>.nd2</code>, <code>.tif</code>, <code>.tiff</code>, <code>.ome.tif</code>, <code>.ome.tiff</code>) are accepted.</p>"},{"location":"registration_module/reference.html#parameters","title":"Parameters","text":"Output folder Either use each input image folder as output folder or specify a custom output folder. To select a custom folder, either paste the path into the text box, click on the Browse button, or drag and drop a folder from an external file manager. Be careful when using a custom folder: if two input files share the same filename (from different folders), the output for both files will be written to the same output files, resulting in data corruption. Output suffix The output filename will correspond to the input filename with an additional <code>_vRG</code> suffix, optionally followed by a user defined suffix (containing only <code>a-z</code>, <code>A-Z</code>, <code>0-9</code> and <code>-</code> characters). The resulting output filenames are shown below the suffix. Channel position If the input image contains more than one channel (<code>C</code> axis), the channel with index specified in <code>channel position</code> will be used for registration (0-based indexing). Note that the selected channel is only used to evaluate the transformation matrix, the output image will contain the same channels as the input image. Projection range and type Registration methods implemented in VLabApp cannot deal with multiple Z sections. If the input image contains a <code>Z</code> axis with multiple Z sections, the chosen range of Z sections will be projected using the chosen projection type (see Z-Projection module for more information). For bright-field images, preliminary results suggest that the <code>std</code> projection type gives the best results.  Note that the Z-projected image is only used to evaluate the transformation matrix, the output image will contain the same Z-sections as the input image. Time point range The transformation matrix can be applied to all time frames, or only to a selected range of time frames. All time frames outside of the selected range are ignored when evaluating the transformation matrix. In addition, registered images obtained by applying this transformation matrix contains only the selected time frames. This option can be useful if the total shift over time is too large, resulting in a very small or empty registered image after cropping to common region shared by all time frames in the image. It can also be used to ignore bad quality time frames. As an alternative, it is possible to use the image cropping module to crop the image before using the registration module. Registration method <p>The following registration method are available (see Appendix: Registration methods for more information):</p> <ul> <li>StackReg by Philippe Thevenaz/EPFL [1] (https://bigwww.epfl.ch/thevenaz/stackreg/).</li> <li>Phase correlation. This method is fast, but tend to fail when too many non-moving artefacts are present in the image (e.g. dust).</li> <li>Feature matching using ORB, BRISK, AKAZE or SIFT algorithms. Preliminary tests on few sample images suggest that registration using  ORB, BRISK, AKAZE or SIFT algorithms give results of similar quality. However, computation time varies significantly. From fastest to slowest: ORB, BRISK, AKAZE, SIFT.</li> </ul> Co-align files with the same unique identifier If checked, all images in the same folder as the input image with same unique identifier (the part of the filename before the first <code>_</code>) and whose filename does not contain <code>_vRG</code> (i.e. not yet registered) will also be transformed using the transformation matrix. This option should not be used if multiple files in the list of input images share the same unique identifier (e.g. <code>smp01_BF.nd2</code> and <code>smp01_WL614.nd</code>), as this will result in data corruption. Do not crop aligned image By default, <code>X</code> and <code>Y</code> axes of the registered images are cropped to the common region shared by all time frames. If the \"Do NOT crop aligned image\" option is checked, the registered image is not cropped. The resulting image has the same dimensions as the input image, and any regions that move outside of the image border are wrapped around using periodic boundary conditions on the <code>X</code> and <code>Y</code> axes. Multi-processing Number of processes to use for coarse-grain parallelization (memory usage increases with the number of processes). This setting is only useful if there are multiple input images, as each input image will be assigned to its own process."},{"location":"registration_module/reference.html#output-files","title":"Output files","text":"<ul> <li>Transformation matrix (see File formats - Transformation matrices for more information).</li> <li>Registered image (see File formats - images and masks for more information).</li> <li>Log file (see File formats - Log files and metadata for more information).</li> </ul> <p>Output filenames are obtained by adding a <code>_vRG</code> suffix to the input filename, optionally followed by a user defined suffix. For example, with input image</p> <pre><code>smp01_BF.nd2\n</code></pre> <p>the output transformation matrix, registered image and log file will have filenames:</p> <pre><code>smp01_BF_vRG.csv\nsmp01_BF_vRG.ome.tif\nsmp01_BF_vRG.log\n</code></pre>"},{"location":"registration_module/reference.html#alignment","title":"Alignment","text":"<p>This module apply existing transformation matrices (created with the registration module) to input images to generate registered images.</p>"},{"location":"registration_module/reference.html#input-files_1","title":"Input files","text":"<p>A list of multi-dimensional images with at least <code>T</code>, <code>X</code>, and <code>Y</code> axes, and optionally <code>Z</code> and <code>C</code> axes and corresponding transformation matrices (see File formats - images and masks and File formats - Transformation matrices for more information).</p> <p>To populate the list, use the Add file, Add folder and Remove selected buttons to add images, folder (all images inside the folder) or remove files from the list. Alternatively, images and folder can be dragged and dropped from an external file manager. When adding files or folders, only files satisfying all filters (click on <code>\u25b6</code> above the list to show filters) are added to the list. By default, only files with a filename not containing <code>_vRG</code> (to avoid already registered images), and ending with one of the accepted file extensions (<code>.nd2</code>, <code>.tif</code>, <code>.tiff</code>, <code>.ome.tif</code>, <code>.ome.tiff</code>) are accepted.</p> <p>For each image, a corresponding transformation matrix file must be in the same folder as the image, and the image and matrix filenames must share the same unique identifier (part of the filename before the first <code>_</code>). If multiple matrix files correspond to an image, the matrix with shortest filename will be selected.</p>"},{"location":"registration_module/reference.html#parameters_1","title":"Parameters","text":"Output folder Either use each input image folder as output folder or specify a custom output folder. To select a custom folder, either paste the path into the text box, click on the Browse button, or drag and drop a folder from an external file manager. Be careful when using a custom folder: if two input files share the same filename (from different folders), the output for both files will be written to the same output file, resulting in data corruption. Output suffix The output filename will correspond to the input filename with an additional <code>_vRG</code> suffix, optionally followed by a user defined suffix (containing only <code>a-z</code>, <code>A-Z</code>, <code>0-9</code> and <code>-</code> characters). The resulting output filenames are shown below the suffix. Do not crop aligned image By default, <code>X</code> and <code>Y</code> axes of the registered images are cropped to the common region shared by all time frames. If the \"Do NOT crop aligned image\" option is checked, the registered image is not cropped. The resulting image has the same dimensions as the input image, and any regions that move outside of the image border are wrapped around using periodic boundary conditions on the <code>X</code> and <code>Y</code> axes. Multi-processing Number of processes to use for coarse-grain parallelization (memory usage increases with the number of processes). This setting is only useful if there are multiple input images, as each input image will be assigned to its own process."},{"location":"registration_module/reference.html#output-files_1","title":"Output files","text":"<ul> <li>Registered image (see File formats - images and masks for more information).</li> <li>Log file (see File formats - Log files and metadata for more information).</li> </ul> <p>Output filenames are obtained by adding a <code>_vRG</code> suffix to the input filename, optionally followed by a user defined suffix. For example, with input image</p> <pre><code>smp01_BF.nd2\n</code></pre> <p>the output registered image and log file will have filenames:</p> <pre><code>smp01_BF_vRG.ome.tif\nsmp01_BF_vRG.log\n</code></pre>"},{"location":"registration_module/reference.html#editing-batch","title":"Editing (batch)","text":"<p>This module allows users to edit the time point range (the range of time frames to use for the transformation) of existing transformation matrices. Note that transformation matrices files are modified in place.</p>"},{"location":"registration_module/reference.html#input-files_2","title":"Input files","text":"<p>A list of transformation matrices (see File formats - Transformation matrices for more information).</p> <p>To populate the list, use the Add file, Add folder and Remove selected buttons to add transformation matrices, folder (all transformation matrices inside the folder) or remove transformation matrices from the list. Alternatively, files and folder can be dragged and dropped from an external file manager.</p> <p>When adding files or folders, only files satisfying all filters (click on <code>\u25b6</code> above the list to show filters) are added to the list. By default, only files with a filename containing <code>_vRG</code> (output of the registration module), and ending with one of the accepted file extensions (<code>.txt</code>, <code>.csv</code>) are accepted.</p>"},{"location":"registration_module/reference.html#parameters_2","title":"Parameters","text":"New time point range Range of time frames to apply the transformation matrix. All time frames outside of the selected range are ignored when evaluating the transformation matrix. In addition, registered images obtained by applying this transformation matrix contains only the selected time frames. This option can be useful if the total shift over time is too large, resulting in a very small or empty registered image after cropping to common region shared by all time frames in the image. It can also be used to ignore bad quality time frames. As an alternative, it is possible to use the image cropping module to crop the image before using the registration module. Multi-processing Number of processes to use for coarse-grain parallelization (memory usage increases with the number of processes). This setting is only useful if there are multiple input images, as each input image will be assigned to its own process."},{"location":"registration_module/reference.html#output-files_2","title":"Output files","text":"<ul> <li>Transformation matrix (see File formats - Transformation matrices for more information).</li> <li>Log file (see File formats - Log files and metadata for more information).</li> </ul> <p>Modification are done in place (the original input matrix and log file are overwritten)</p>"},{"location":"registration_module/reference.html#editing-manual","title":"Editing (manual)","text":"<p>This module allows users to edit an existing transformation matrix using napari.  Note that the transformation matrix is modified in place.</p>"},{"location":"registration_module/reference.html#input-files_3","title":"Input files","text":"<ul> <li>A transformation matrix (see File formats - Transformation matrices for more information)</li> <li>A multi-dimensional image with at least <code>T</code>, <code>X</code>, and <code>Y</code> axes, and optionally <code>Z</code> and <code>C</code> axes (see File formats - images and masks for more information). Important: this image should not be registered. Ideally, the image used to create the transformation matrix should be selected here. </li> </ul> <p>To select a transformation matrix or an image, either paste the path into the text box, click on the Browse button, or drag and drop a file from an external file manager.</p> <p>Note that when filling the image or the transformation matrix field while the other field is empty, the empty field is populated by a best guess.</p>"},{"location":"registration_module/reference.html#usage","title":"Usage","text":"Figure 1: Manually editing a registration matrix with napari <p>The unregistered image opens in napari (Figure 1A), with one layer per channel (<code>C</code> axis, Figure 1B), one slider for the time axis (<code>T</code>, Figure 1C) and one slider the <code>Z</code> axis if the image has a <code>Z</code> axis  (Figure 1C).</p> <p>A graphical representation of the transformation matrix is shown in the lower part of the window (Figure 1D), with x (red) and y (blue) coordinates of the image offset (vertical axis) as a function of time (horizontal axis). The full transformation matrix evaluated for all time frames is shown with dashed lines and the final transformation matrix, limited to a selected range of time frames, is shown with plain lines and points.</p> <p>The transformation matrix is also represented by a green control point (Figure 1E) overlaid on the image (layer \"Alignment points\"). The position of the control point is transformed using the transformation matrix (i.e. it should ideally follow the cells in the image). By default, when changing the time frame (using the <code>T</code> slider), the view follow the control point, which seems to have a fixed position. To keep the image at fixed position, uncheck the \"Move view with alignment point\" option (Figure 1F).</p> <p>By default, the control point is placed at the center of the image. However, it might be better to place it at a more remarkable position (e.g. at the center of a cell). To globally move the control point for all time frames (without changing the transformation matrix), click at the desired position while pressing the SHIFT key (make sure that the layer \"Alignment points\" is selected, Figure 1B).</p> <p>The transformation matrix is modified by adjusting the position of the control point at the current time frame (selected with the Z slider), from first to current time frame, or from current time frame to last (the desired behavior can be selected in the right part of the window, Figure 1G). To move the control point for the selected range of frame, click at the desired position while pressing the CTRL key (or CMD key with Mac OS X).</p> <p>The range of time frames to use for the transformation can be set using the \"From\" and \"To\" fields in the right part of the window (Figure 1H).</p> <p>To save the transformation matrix, click on the Save button (Figure 1I). Note that with this module, the transformation matrix file is only modified when clicking on the Save button.</p>"},{"location":"registration_module/reference.html#output-files_3","title":"Output files","text":"<ul> <li>Transformation matrix (see File formats - Transformation matrices for more information).</li> <li>Log file (see File formats - Log files and metadata for more information).</li> </ul> <p>Modification are done in place (the original input matrix and log file are overwritten when clicking on the Save button)</p>"},{"location":"registration_module/reference.html#appendix-registration-methods","title":"Appendix: Registration methods","text":"<p>The following registration methods are implemented:</p> <ul> <li> <p>StackReg: Registration using pyStackReg with translation transformation. pyStackReg is a Python/C++ port of the ImageJ extension TurboReg/StackReg written by Philippe Thevenaz/EPFL [1].</p> </li> <li> <p>Phase correlation: Registration using the phase correlation method implemented in OpenCV (function <code>phaseCorrelate()</code>), which uses the Fourrier shift theorem to detect translational shift in the frequency domain (see https://en.wikipedia.org/wiki/Phase_correlation). This method is fast, but tend to fail when too many non-moving artefacts are present in the image (e.g. dust).</p> </li> <li> <p>Feature matching: Four variants of the \"feature matching\" registration methods are available (ORB, BRISK, AKAZE and SIFT). In this method, registration is performed in three steps:</p> <ol> <li> <p>Feature (keypoints) detection and evaluation of the descriptors using methods implemented in OpenCV. Four keypoints detector an descriptor extractor algorithms are available:</p> <ul> <li>ORB (Oriented FAST and Rotated BRIEF) [2].</li> <li>BRISK (Binary Robust invariant scalable keypoints) [3].</li> <li>AKAZE (Accelerated-KAZE) [4].</li> <li>SIFT (scale-invariant feature transform) [5].</li> </ul> </li> <li> <p>Feature matching. Features found in consecutive image frames are matched using the FLANN-based descriptor matcher implemented in  OpenCV  (FLANN stands for Fast Library for Approximate Nearest Neighbors). Matches are further filtered using the distance ratio test proposed by Lowe [5] (with threshold 0.75).</p> </li> <li> <p>Parameter estimation using RANSAC. The shift between consecutive image frames is then estimated with the Random sample consensus (RANSAC) method implemented in scikit-image using a custom transformation model with translation only.</p> </li> </ol> <p>Preliminary tests on few sample images suggest that registration using  ORB, BRISK, AKAZE or SIFT algorithms give results of similar quality. Note that the scale and rotational invariance is not so important when considering consecutive image frames, as the size and orientation of the features is not expected to change on short time scale. However, computation time varies significantly. From fastest to slowest: ORB, BRISK, AKAZE, SIFT.</p> </li> </ul>"},{"location":"registration_module/reference.html#references","title":"References","text":"<p>[1] P. Thevenaz, U. E. Ruttimann and M. Unser (1998). A pyramid approach to subpixel registration based on intensity. IEEE Transactions on Image Processing, 7(1), 27\u201341.</p> <p>[2] E. Rublee, V. Rabaud, K. Konolige and G. Bradski (2011). ORB: An efficient alternative to SIFT or SURF. Procedings of the IEEE International Conference on Computer Vision, 2564\u20132571.</p> <p>[3] S. Leutenegger, M. Chli and R. Y. Siegwart (2011). Brisk: Binary robust invariant scalable keypoints.  Procedings of the IEEE International Conference on Computer Vision, 2548\u20132555.</p> <p>[4] P. F. Alcantarilla, J. Nuevo and A. Bartoli (2013). Fast explicit diffusion for accelerated features in nonlinear scale spaces.  Procedings of the British Machine Vision Conference 2013, 13.1-13.11.</p> <p>[5] D. G. Lowe (2004). Distinctive Image Features from Scale-Invariant Keypoints. International Journal of Computer Vision, 60(2), 91\u2013110.</p>"},{"location":"segmentation_module/reference.html","title":"Segmentation module","text":"<p>The segmentation module use Cellpose v3 [1-3] to perform cell segmentation and generate a segmentation mask.</p>"},{"location":"segmentation_module/reference.html#input-files","title":"Input files","text":"<p>A list of multi-dimensional images with at least <code>X</code> and <code>Y</code> axes, and optionally <code>C</code>, <code>Z</code> and <code>T</code> axes (see File formats - images and masks for more information).</p> <p>To populate the list, use the Add file, Add folder and Remove selected buttons to add images, folder (all images inside the folder) or remove images from the list. Alternatively, images and folder can be dragged and dropped from an external file manager.</p> <p>When adding files or folders, only files satisfying all filters (click on <code>\u25b6</code> above the list to show filters) are added to the list.  By default, only files with a filename containing <code>_BF</code> (image with a unique bright-field channel) and ending with one of the accepted file extensions (<code>.nd2</code>, <code>.tif</code>, <code>.tiff</code>, <code>.ome.tif</code>, <code>.ome.tiff</code>) are accepted.</p>"},{"location":"segmentation_module/reference.html#parameters","title":"Parameters","text":"Output folder Either use each input image folder as output folder or specify a custom output folder. To select a custom folder, either paste the path into the text box, click on the Browse button, or drag and drop a folder from an external file manager. Be careful when using a custom folder: if two input files share the same filename (from different folders), the output for both files will be written to the same output file, resulting in data corruption. Output suffix The output filename will correspond to the input filename with an additional <code>_vSM</code> suffix, optionally followed by a user defined suffix (containing only <code>a-z</code>, <code>A-Z</code>, <code>0-9</code> and <code>-</code> characters). The resulting output filenames are shown below the suffix. Segmentation method The segmentation method to use. Currently only <code>Cellpose</code> (https://www.cellpose.org/). Model type <p>For Cellpose:</p> <ul> <li><code>User trained model</code>: a user trained model can be obtained by finetuning a pretrained Cellpose model on a collection of annotated images similar to the input images (see section \"Training\" in Cellpose documentation https://cellpose.readthedocs.io/en/v3.1.1.1/). Note that the Ground truth generator module can be used to generate a collection of annotated images (training set) for Cellpose.</li> <li>Built-in models: use one of the Cellpose built-in models (<code>cyto</code>, <code>cyto2</code>, <code>cyto3</code>, <code>nuclei</code>, <code>tissuenet_cp3</code>, <code>livecell_cp3</code>, <code>yeast_PhC_cp3</code>, <code>yeast_BF_cp3</code>, <code>bact_phase_cp3</code>, <code>bact_fluor_cp3</code>, <code>deepbacs_cp3</code> and <code>cyto2_cp3</code>).</li> </ul> Model path to the Cellpose user trained model. To select a model, either paste the path into the text box, click on the Browse button, or drag and drop a file from an external file manager. This parameter is available only for Cellpose user trained models. Diameter Expected cell diameter (pixel). If 0, use Cellpose built-in model to estimate diameter (available only for <code>cyto</code>, <code>cyto2</code>, <code>cyto3</code> and <code>nuclei</code> models). For more information, see section \"Models\" in Cellpose documentation https://cellpose.readthedocs.io/en/v3.1.1.1/. This parameter is available only for Cellpose built-in models. For user trained models, the median diameter estimated on the training set is used. Cellprob threshold cellprob threshold for Cellpose. For more information, see section \"Settings\" in Cellpose documentation https://cellpose.readthedocs.io/en/v3.1.1.1/. This parameter is available only for Cellpose, click on <code>\u25b6</code> to show. Flow threshold cellprob threshold for Cellpose. For more information, see section \"Settings\" in Cellpose documentation https://cellpose.readthedocs.io/en/v3.1.1.1/. This parameter is available only for Cellpose, click on <code>\u25b6</code> to show. Channel position If the input image contains more than one channel (<code>C</code> axis), the channel with index specified in <code>channel position</code> will be used for segmentation (0-based indexing). Projection range and type If the input image contains a <code>Z</code> axis with multiple Z sections, the chosen range of Z sections will be projected using the chosen projection type (see Z-Projection module for more information). Note that for best results, the segmentation model used should have been trained on the selected type of Z-projected images. Use GPU Use a GPU if available. Using this option prevents from using CPU parallelization (use coarse grain parallelization and number of processes are ignored). Use coarse grain parallelization If checked, each input file is assigned to its own process. Otherwise, use fine-grained parallelization on the time frames. Coarse grain parallelization should be used when there are more input files than processes and enough memory (memory usage increases with the number of processes). Number of processes Number of processes to use. Show results in napari If checked, the input image and resulting segmentation mask are shown in napari after segmentation.  This option is disabled if there is more than one input image."},{"location":"segmentation_module/reference.html#output-files","title":"Output files","text":"<ul> <li>Segmentation mask (see File formats - images and masks for more information).</li> <li>Log file (see File formats - Log files and metadata for more information).</li> </ul> <p>Output filenames are obtained by adding a <code>_vSM</code> suffix to the input filename, optionally followed by a user defined suffix. For example, with input image</p> <pre><code>smp01_BF.nd2\n</code></pre> <p>the output segmentation mask and log file will have filenames:</p> <pre><code>smp01_BF_vSM.ome.tif\nsmp01_BF_vSM.log\n</code></pre>"},{"location":"segmentation_module/reference.html#references","title":"References","text":"<p>[1] C. Stringer, T. Wang, M. Michaelos and M. Pachitariu (2021). Cellpose: a generalist algorithm for cellular segmentation. Nature Methods 18, 100\u2013106.</p> <p>[2] M. Pachitariu and C. Stringer (2022). Cellpose 2.0: how to train your own model. Nature Methods 19, 1634\u20131641.</p> <p>[3] C. Stringer and M. Pachitariu (2025). Cellpose3: one-click image restoration for improved cellular segmentation. Nature Methods 22, 592-599.</p>"},{"location":"viewer_image_mask_graph_module/reference.html","title":"View image, mask and graph","text":"<p>This module allows users to view an image, a segmentation mask and/or a cell tracking graph using napari.</p>"},{"location":"viewer_image_mask_graph_module/reference.html#input-files","title":"Input files","text":"Image A multi-dimensional image with at least <code>X</code> and <code>Y</code> axes, and optionally <code>C</code>, <code>Z</code> and <code>T</code> axes (see File formats - images and masks for more information). This field is optional.  Segmentation mask A multi-dimensional segmentation mask with at least <code>X</code> and <code>Y</code> axes, and optionally <code>Z</code> and <code>T</code> axes (see File formats - images and masks for more information). This field is optional, but must be filled if a cell tracking graph is specified. Cell tracking graph A cell tracking graph (see File formats - Cell tracking graphs for more information). This field is optional. Note that a cell tracking graph cannot be viewed without the corresponding segmentation mask. <p>To select a file, either paste the path into the text box, click on the Browse button, or drag and drop a file from an external file manager.</p> <p>When filling the segmentation mask or cell tracking graph field, VLabApp try to fill the other empty fields by searching for corresponding files in the same directory. Edit a field to erase the proposed files (e.g. type any character then erase it).</p>"},{"location":"viewer_image_mask_graph_module/reference.html#usage","title":"Usage","text":"Figure 1: napari window with a segmentation mask overlaid on top of a bright-field image. Figure 2: napari window with the cell tracking graph associated with the segmentation mask shown in Figure 1. <p>If specified, the image and segmentation mask open in one napari window (Figure 1A), with one layer per image channel (<code>C</code> axis) and one layer for the segmentation mask (Figure 1B). If the image or the mask has a <code>T</code> (time) or a <code>Z</code> axis, corresponding sliders will be available at the bottom of the window (Figure 1C). If specified, the cell track graph opens in a second napari window (Figure 2)..</p> <p>Both windows support panning and zooming with a mouse or touchpad. Selecting a specific <code>T</code> or <code>Z</code> axis position can be done using the respective axis slider.</p> <p>For the following, make sure that the \"Cell mask\" layer is selected (Figure 1B). When hovering over a labelled region in the segmentation mask, the corresponding mask id is shown in the status bar. Similarly, when hovering over a vertex in the cell tracking graph, the corresponding time frame and mask id are shown in the status bar. Click (left mouse button) on a labelled region in the segmentation mask to center the view on the corresponding vertex in the cell tracking graph view. Click (left mouse button) on a vertex of the cell tracking graph to center the segmentation mask view on the corresponding labelled region and time frame (<code>T</code> axis slider).</p> <p>Warning: when viewing a cell tracking graph (two napari windows), use the Quit button to close napari windows (Figure 1D). Do not use the \"Close window\" option in the \"File\" menu nor the window close button , as it may crash the application. Do not use \"Exit\" option in the \"File\" menu, as it will close the full VLabApp application.</p>"},{"location":"viewer_metadata_module/reference.html","title":"View metadata","text":"<p>This module displays VLabApp metadata contained in files generated with VLabApp (see File formats - Log files and metadata for more information).</p> <p>To select a file, either paste the path into the text box, click on the Browse button, or drag and drop a file from an external file manager.</p> <p>Accepted input file types:</p> <ul> <li>Images (see File formats - images and masks for more information).</li> <li>Segmentation masks (see File formats - images and masks for more information).</li> <li>Cell tracking graphs  (see File formats - Cell tracking graphs for more information).</li> <li>Registration matrices (see File formats - Transformation matrices for more information).</li> </ul>"},{"location":"viewer_registration_module/reference.html","title":"View registration matrix","text":"<p>This module allows users to view a transformation matrix using napari.</p>"},{"location":"viewer_registration_module/reference.html#input-files","title":"Input files","text":"Image (before registration) A multi-dimensional image with at least <code>T</code>, <code>X</code>, and <code>Y</code> axes, and optionally <code>Z</code> and <code>C</code> axes (see File formats - images and masks for more information). Important: this image should not be registered. Ideally, the image used to create the transformation matrix should be selected here. Registration matrix A transformation matrix (see File formats - Transformation matrices for more information) <p>To select a file, either paste the path into the text box, click on the Browse button, or drag and drop a file from an external file manager.</p> <p>Note that when filling the image or the transformation matrix field while the other field is empty, the empty field is populated by a best guess.  Edit a field to erase the proposed files (e.g. type any character then erase it).</p>"},{"location":"viewer_registration_module/reference.html#usage","title":"Usage","text":"Figure 1: Viewing a registration matrix with napari <p>The unregistered image opens in napari (Figure 1A), with one layer per channel (<code>C</code> axis, Figure 1B), one slider for the time axis (<code>T</code>, Figure 1C) and one slider the <code>Z</code> axis if the image has a <code>Z</code> axis  (Figure 1C).</p> <p>A graphical representation of the transformation matrix is shown in the lower part of the window (Figure 1D), with x (red) and y (blue) coordinates of the image offset (vertical axis) as a function of time (horizontal axis). The full transformation matrix evaluated for all time frames is shown with dashed lines and the final transformation matrix, limited to a selected range of time frames, is shown with plain lines and points.</p> <p>The transformation matrix is also represented by a green control point (Figure 1E) overlaid on the image (layer \"Alignment points\"). The position of the control point is transformed using the transformation matrix (i.e. it should ideally follow the cells in the image). By default, when changing the time frame (using the <code>T</code> slider), the view follow the control point, which seems to have a fixed position. To keep the image at fixed position, uncheck the \"Move view with alignment point\" option (Figure 1F).</p> <p>By default, the control point is placed at the center of the image. However, it might be better to place it at a more remarkable position (e.g. at the center of a cell). To  move the control point for all time frames, click at the desired position while pressing the SHIFT key (make sure that the layer \"Alignment points\" is selected, Figure 1B).</p>"},{"location":"zprojection_module/reference.html","title":"Z-Projection module","text":"<p>The Z-Projection module performs a Z-stack projection of an image.</p>"},{"location":"zprojection_module/reference.html#input-files","title":"Input files","text":"<p>A list of multi-dimensional images with at least <code>X</code>, <code>Y</code>, and <code>Z</code> axes, and optionally <code>C</code> and <code>T</code> axes (see File formats - images and masks for more information).</p> <p>To populate the list, use the Add file, Add folder and Remove selected buttons to add images, folder (all images inside the folder) or remove images from the list. Alternatively, images and folder can be dragged and dropped from an external file manager.</p> <p>When adding files or folders, only files satisfying all filters (click on <code>\u25b6</code> above the list to show filters) are added to the list. By default, only files ending with one of the accepted file extensions (<code>.nd2</code>, <code>.tif</code>, <code>.tiff</code>, <code>.ome.tif</code>, <code>.ome.tiff</code>) are accepted.</p>"},{"location":"zprojection_module/reference.html#parameters","title":"Parameters","text":"Output folder Either use each input image folder as output folder or specify a custom output folder. To select a custom folder, either paste the path into the text box, click on the Browse button, or drag and drop a folder from an external file manager. Be careful when using a custom folder: if two input files share the same filename (from different folders), the output for both files will be written to the same output file, resulting in data corruption. Output suffix The output filename will correspond to the input filename with an additional <code>_vPR&lt;ref&gt;&lt;range&gt;&lt;proj&gt;</code> suffix, where <code>&lt;ref&gt;</code> is the reference Z-section (<code>b</code> for best focus or <code>f</code> for fixed range), <code>&lt;range&gt;</code> is the range of Z-sections (one integer for range around Z-section with best focus or two integers  min and max separated by a <code>-</code> for fixed Z-section range) and <code>&lt;proj&gt;</code> is the projection type (<code>none</code>, <code>max</code>, <code>min</code>, <code>mean</code>, <code>median</code> or <code>std</code>).  The resulting output filenames are shown below the suffix. It is not possible to set a user defined suffix in this module. Projection range <p>Range of Z sections to project.</p> <ul> <li>Z-section with best focus: select only the Z-section with best focus.</li> <li>Range around Z-section with best focus: select all Z sections with \\(Z\\) in the interval \\([Z_{best}-r,Z_{best}+r]\\), where \\(Z_{best}\\) is the Z section with best focus and \\(r\\) is the range.</li> <li>Fixed range from \\(Z_{min}\\) to \\(Z_{max}\\): select all Z-sections with \\(Z_{min}\\leq Z \\leq Z_{max}\\).</li> <li>All Z-sections: select all Z-sections.</li> </ul> <p>The selected Z-sections are then projected using the chosen projection type (see Appendix: Z-Projection methods for more information).</p> Projection type summary statistics to use when projecting the selected Z-sections (<code>max</code>, <code>min</code>, <code>mean</code>, <code>median</code> or <code>std</code>). See Appendix: Z-Projection methods for more information. Multi-processing Number of processes to use for coarse-grain parallelization (memory usage increases with the number of processes). This setting is only useful if there are multiple input images, as each input image will be assigned to its own process."},{"location":"zprojection_module/reference.html#output-files","title":"Output files","text":"<ul> <li>Z-projected image (see File formats - images and masks for more information).</li> <li>Log file (see File formats - Log files and metadata for more information).</li> </ul> <p>Output filenames are obtained by adding a <code>_vPR&lt;ref&gt;&lt;range&gt;&lt;proj&gt;</code> suffix to the input filename. For example, with input image</p> <pre><code>smp01_BF.nd2\n</code></pre> <p>and a mean projection over the fixed range from 3 to 7, the output Z-projected image and log file will have filenames:</p> <pre><code>smp01_BF_vPRf3-7mean.ome.tif\nsmp01_BF_vPRf3-7mean.log\n</code></pre>"},{"location":"zprojection_module/reference.html#appendix-z-projection-methods","title":"Appendix: Z-Projection methods","text":""},{"location":"zprojection_module/reference.html#z-projection","title":"Z-Projection","text":"<p>We consider the problem of reducing a Z-stack of 2D images to a unique 2D image (Z-projection).</p> <p>The value \\(v(x,y)\\) of the pixel at position \\((x,y)\\) in the new image is obtained by summarizing the values of the pixels at the same position over all Z sections (or a subset of Z sections) using a given summary statistics (e.g. mean, median, max,...).</p> <p>The subset of Z sections used for projection can be:</p> <ul> <li>all Z sections.</li> <li>a fixed range of Z sections.</li> <li>a range of Z sections around the Z section with best focus.</li> <li>only the Z section with best focus.</li> </ul>"},{"location":"zprojection_module/reference.html#all-z-sections","title":"All Z sections","text":"<p>All Z sections are used for the projection.</p>"},{"location":"zprojection_module/reference.html#fixed-range-of-z-sections","title":"Fixed range of Z sections","text":"<p>The subset of Z sections used for projection is chosen as all Z sections within the fixed interval \\(Z\\in[Z_\\text{min},Z_\\text{max}]\\), with user-defined \\(Z_\\text{min}\\) and \\(Z_\\text{max}\\).</p> <p>Note:</p> <ul> <li>\\(Z_\\text{min}\\) and \\(Z_\\text{max}\\) are called \"From\" and \"To\" in the GUI.</li> </ul>"},{"location":"zprojection_module/reference.html#range-of-z-sections-around-the-z-section-with-best-focus","title":"Range of Z sections around the Z section with best focus.","text":"<p>The subset of Z sections used for projection is chosen as all Z sections within a user specified window around the Z section with best focus. I.e. Z sections with \\(Z\\in \\{Z_\\text{best}-\\Delta_Z,Z_\\text{best}-\\Delta_Z +1,\\cdots,Z_\\text{best}+\\Delta_Z\\}\\), where \\(Z_\\text{best}\\) corresponds to the Z-section with best focus and \\(\\Delta_Z\\) is the size of the Z window.</p> <p>If \\(Z_\\text{best}\\) and \\(\\Delta_Z\\) are such that some values in \\(\\{Z_\\text{best}-\\Delta_Z,Z_\\text{best}-\\Delta_Z +1,\\cdots,Z_\\text{best}+\\Delta_Z\\}\\) are outside the range of Z sections existing in the image, then the set is shifted towards valid values of Z. E.g. a Z-stack with 11 sections (Z=0, 1, ..., 10), \\(\\Delta_Z=3\\) and \\(Z_\\text{best}=1\\): The set of Z sections to be used for projection is \\(\\{-2,-1,0,1,2,3,4\\}\\), which contains invalid values (-2 and -1). It is thus shifted in the positive Z direction to avoid negative values \\(\\{0,1,2,3,4,5,6\\}\\) </p> <p>To estimate \\(Z_\\text{best}\\) (see Figure 1 and 2), the tenengrad</p> \\[T(x,y) = \\sqrt{\\left(\\frac{\\partial v(x,y)}{\\partial x}\\right)^2 + \\left(\\frac{\\partial v(x,y)}{\\partial y}\\right)^2}\\] <p>of each Z section is estimated using Sobel operators of size 3x3. The tenengrad can be interpreted as a measure of the local slope. In particular, it is large for region of the image with sharp variations (such as edges) and zero for regions with constant pixel intensities.</p> <p>The \"sharpness\" is then estimated, for each Z, as the variance of the tenengrad of the corresponding Z section (Figure 1C and 2C). The sharpness is then smoothed using a running mean with window of size 3. Finally, \\(Z_\\text{best}\\) is obtained as the \\(Z\\) at which the smoothed sharpness reaches its maximum.</p> Figure 1: determination of Z section with best focus. Panel A: Z sections of a bright-field image. Panel B: Tenengrad of the Z sections. Panel C: Sharpness of each Z section (black points) as a function of Z together with the smoothed sharpness (blue). Figure 2: same as Figure 1 but with a fluorescence image. <p>Note:</p> <ul> <li>The window size \\(\\Delta_Z\\) is called \"Projection range\" in the GUI.</li> </ul>"},{"location":"zprojection_module/reference.html#z-section-with-best-focus","title":"Z section with best focus","text":"<p>The stack of Z sections is simply replaced by the Z section with best focus (obtained as described above).</p>"}]}